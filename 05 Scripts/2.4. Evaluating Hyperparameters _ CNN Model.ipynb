{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5259ce5",
   "metadata": {},
   "source": [
    "# 2.4. Evaluating Hyperparameters _ CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f6b37",
   "metadata": {},
   "source": [
    "## The following script contains the following:\n",
    "### 1. Import data libraries and data sets\n",
    "### 2. Preprocessing the data frames\n",
    "### 3. Bayesian optimization function \n",
    "### 4. Build and run CNN keras models\n",
    "### 5. Run confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2180d",
   "metadata": {},
   "source": [
    "## 01. Import data libraries and data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4eb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Conv1D, Conv2D, Dense, BatchNormalization, Flatten, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(negative_slope=0.1)\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98457bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress scientific notation for easier analysis profiling\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set display options to show all columns without truncation\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee30e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create path\n",
    "path = r'C:\\Users\\Quinn\\Documents\\CF - Data Analysis\\Machine Learning\\ClimateWins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83c7151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>BASEL_cloud_cover</th>\n",
       "      <th>BASEL_humidity</th>\n",
       "      <th>BASEL_pressure</th>\n",
       "      <th>BASEL_global_radiation</th>\n",
       "      <th>BASEL_precipitation</th>\n",
       "      <th>BASEL_sunshine</th>\n",
       "      <th>BASEL_temp_mean</th>\n",
       "      <th>BASEL_temp_min</th>\n",
       "      <th>BASEL_temp_max</th>\n",
       "      <th>BELGRADE_cloud_cover</th>\n",
       "      <th>BELGRADE_humidity</th>\n",
       "      <th>BELGRADE_pressure</th>\n",
       "      <th>BELGRADE_global_radiation</th>\n",
       "      <th>BELGRADE_precipitation</th>\n",
       "      <th>BELGRADE_sunshine</th>\n",
       "      <th>BELGRADE_temp_mean</th>\n",
       "      <th>BELGRADE_temp_min</th>\n",
       "      <th>BELGRADE_temp_max</th>\n",
       "      <th>BUDAPEST_cloud_cover</th>\n",
       "      <th>BUDAPEST_humidity</th>\n",
       "      <th>BUDAPEST_pressure</th>\n",
       "      <th>BUDAPEST_global_radiation</th>\n",
       "      <th>BUDAPEST_precipitation</th>\n",
       "      <th>BUDAPEST_sunshine</th>\n",
       "      <th>BUDAPEST_temp_mean</th>\n",
       "      <th>BUDAPEST_temp_min</th>\n",
       "      <th>BUDAPEST_temp_max</th>\n",
       "      <th>DEBILT_cloud_cover</th>\n",
       "      <th>DEBILT_humidity</th>\n",
       "      <th>DEBILT_pressure</th>\n",
       "      <th>DEBILT_global_radiation</th>\n",
       "      <th>DEBILT_precipitation</th>\n",
       "      <th>DEBILT_sunshine</th>\n",
       "      <th>DEBILT_temp_mean</th>\n",
       "      <th>DEBILT_temp_min</th>\n",
       "      <th>DEBILT_temp_max</th>\n",
       "      <th>DUSSELDORF_cloud_cover</th>\n",
       "      <th>DUSSELDORF_humidity</th>\n",
       "      <th>DUSSELDORF_pressure</th>\n",
       "      <th>DUSSELDORF_global_radiation</th>\n",
       "      <th>DUSSELDORF_precipitation</th>\n",
       "      <th>DUSSELDORF_sunshine</th>\n",
       "      <th>DUSSELDORF_temp_mean</th>\n",
       "      <th>DUSSELDORF_temp_min</th>\n",
       "      <th>DUSSELDORF_temp_max</th>\n",
       "      <th>HEATHROW_cloud_cover</th>\n",
       "      <th>HEATHROW_humidity</th>\n",
       "      <th>HEATHROW_pressure</th>\n",
       "      <th>HEATHROW_global_radiation</th>\n",
       "      <th>HEATHROW_precipitation</th>\n",
       "      <th>HEATHROW_sunshine</th>\n",
       "      <th>HEATHROW_temp_mean</th>\n",
       "      <th>HEATHROW_temp_min</th>\n",
       "      <th>HEATHROW_temp_max</th>\n",
       "      <th>KASSEL_humidity</th>\n",
       "      <th>KASSEL_pressure</th>\n",
       "      <th>KASSEL_global_radiation</th>\n",
       "      <th>KASSEL_precipitation</th>\n",
       "      <th>KASSEL_sunshine</th>\n",
       "      <th>KASSEL_temp_mean</th>\n",
       "      <th>KASSEL_temp_min</th>\n",
       "      <th>KASSEL_temp_max</th>\n",
       "      <th>LJUBLJANA_cloud_cover</th>\n",
       "      <th>LJUBLJANA_humidity</th>\n",
       "      <th>LJUBLJANA_pressure</th>\n",
       "      <th>LJUBLJANA_global_radiation</th>\n",
       "      <th>LJUBLJANA_precipitation</th>\n",
       "      <th>LJUBLJANA_sunshine</th>\n",
       "      <th>LJUBLJANA_temp_mean</th>\n",
       "      <th>LJUBLJANA_temp_min</th>\n",
       "      <th>LJUBLJANA_temp_max</th>\n",
       "      <th>MAASTRICHT_cloud_cover</th>\n",
       "      <th>MAASTRICHT_humidity</th>\n",
       "      <th>MAASTRICHT_pressure</th>\n",
       "      <th>MAASTRICHT_global_radiation</th>\n",
       "      <th>MAASTRICHT_precipitation</th>\n",
       "      <th>MAASTRICHT_sunshine</th>\n",
       "      <th>MAASTRICHT_temp_mean</th>\n",
       "      <th>MAASTRICHT_temp_min</th>\n",
       "      <th>MAASTRICHT_temp_max</th>\n",
       "      <th>MADRID_cloud_cover</th>\n",
       "      <th>MADRID_humidity</th>\n",
       "      <th>MADRID_pressure</th>\n",
       "      <th>MADRID_global_radiation</th>\n",
       "      <th>MADRID_precipitation</th>\n",
       "      <th>MADRID_sunshine</th>\n",
       "      <th>MADRID_temp_mean</th>\n",
       "      <th>MADRID_temp_min</th>\n",
       "      <th>MADRID_temp_max</th>\n",
       "      <th>MUNCHENB_cloud_cover</th>\n",
       "      <th>MUNCHENB_humidity</th>\n",
       "      <th>MUNCHENB_global_radiation</th>\n",
       "      <th>MUNCHENB_precipitation</th>\n",
       "      <th>MUNCHENB_sunshine</th>\n",
       "      <th>MUNCHENB_temp_mean</th>\n",
       "      <th>MUNCHENB_temp_min</th>\n",
       "      <th>MUNCHENB_temp_max</th>\n",
       "      <th>OSLO_cloud_cover</th>\n",
       "      <th>OSLO_humidity</th>\n",
       "      <th>OSLO_pressure</th>\n",
       "      <th>OSLO_global_radiation</th>\n",
       "      <th>OSLO_precipitation</th>\n",
       "      <th>OSLO_sunshine</th>\n",
       "      <th>OSLO_temp_mean</th>\n",
       "      <th>OSLO_temp_min</th>\n",
       "      <th>OSLO_temp_max</th>\n",
       "      <th>SONNBLICK_cloud_cover</th>\n",
       "      <th>SONNBLICK_humidity</th>\n",
       "      <th>SONNBLICK_pressure</th>\n",
       "      <th>SONNBLICK_global_radiation</th>\n",
       "      <th>SONNBLICK_precipitation</th>\n",
       "      <th>SONNBLICK_sunshine</th>\n",
       "      <th>SONNBLICK_temp_mean</th>\n",
       "      <th>SONNBLICK_temp_min</th>\n",
       "      <th>SONNBLICK_temp_max</th>\n",
       "      <th>STOCKHOLM_cloud_cover</th>\n",
       "      <th>STOCKHOLM_pressure</th>\n",
       "      <th>STOCKHOLM_global_radiation</th>\n",
       "      <th>STOCKHOLM_precipitation</th>\n",
       "      <th>STOCKHOLM_sunshine</th>\n",
       "      <th>STOCKHOLM_temp_mean</th>\n",
       "      <th>STOCKHOLM_temp_min</th>\n",
       "      <th>STOCKHOLM_temp_max</th>\n",
       "      <th>VALENTIA_cloud_cover</th>\n",
       "      <th>VALENTIA_humidity</th>\n",
       "      <th>VALENTIA_pressure</th>\n",
       "      <th>VALENTIA_global_radiation</th>\n",
       "      <th>VALENTIA_precipitation</th>\n",
       "      <th>VALENTIA_sunshine</th>\n",
       "      <th>VALENTIA_temp_mean</th>\n",
       "      <th>VALENTIA_temp_min</th>\n",
       "      <th>VALENTIA_temp_max</th>\n",
       "      <th>KASSEL_cloud_cover</th>\n",
       "      <th>MUNCHENB_pressure</th>\n",
       "      <th>STOCKHOLM_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19600101</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.70</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>7.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.40</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>5.10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.30</td>\n",
       "      <td>7.40</td>\n",
       "      <td>11.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>9.40</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.90</td>\n",
       "      <td>3.90</td>\n",
       "      <td>9.40</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>8.50</td>\n",
       "      <td>11.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.60</td>\n",
       "      <td>4.40</td>\n",
       "      <td>10.80</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.90</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.90</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-5.90</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.70</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>10.90</td>\n",
       "      <td>8</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19600102</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.10</td>\n",
       "      <td>6.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>10.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7.70</td>\n",
       "      <td>6.40</td>\n",
       "      <td>8.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.20</td>\n",
       "      <td>7.40</td>\n",
       "      <td>11.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>3.90</td>\n",
       "      <td>10.60</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.70</td>\n",
       "      <td>6.80</td>\n",
       "      <td>9.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.10</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>5.50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8.60</td>\n",
       "      <td>7.50</td>\n",
       "      <td>9.90</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9.80</td>\n",
       "      <td>7.40</td>\n",
       "      <td>12.20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.10</td>\n",
       "      <td>6.20</td>\n",
       "      <td>4.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.50</td>\n",
       "      <td>-10.50</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.90</td>\n",
       "      <td>5.60</td>\n",
       "      <td>12.10</td>\n",
       "      <td>6</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19600103</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>5.10</td>\n",
       "      <td>9.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>6.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5.30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>4.60</td>\n",
       "      <td>9.90</td>\n",
       "      <td>7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.10</td>\n",
       "      <td>6.90</td>\n",
       "      <td>9.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8.40</td>\n",
       "      <td>6.10</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.90</td>\n",
       "      <td>5.50</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>8.60</td>\n",
       "      <td>6.40</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.50</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.50</td>\n",
       "      <td>8.10</td>\n",
       "      <td>12.90</td>\n",
       "      <td>8</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19600104</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>3.80</td>\n",
       "      <td>10.60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>3.60</td>\n",
       "      <td>10.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6.70</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>5.20</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.70</td>\n",
       "      <td>10.30</td>\n",
       "      <td>4.50</td>\n",
       "      <td>16.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>-12.90</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.30</td>\n",
       "      <td>10.60</td>\n",
       "      <td>6</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>19600105</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>11.20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.70</td>\n",
       "      <td>6.20</td>\n",
       "      <td>11.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.90</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.70</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>11.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.80</td>\n",
       "      <td>12.10</td>\n",
       "      <td>8.20</td>\n",
       "      <td>16.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.10</td>\n",
       "      <td>-9.30</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.70</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>7</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      DATE  MONTH  BASEL_cloud_cover  BASEL_humidity  \\\n",
       "0           0  19600101      1                  7            0.85   \n",
       "1           1  19600102      1                  6            0.84   \n",
       "2           2  19600103      1                  8            0.90   \n",
       "3           3  19600104      1                  3            0.92   \n",
       "4           4  19600105      1                  6            0.95   \n",
       "\n",
       "   BASEL_pressure  BASEL_global_radiation  BASEL_precipitation  \\\n",
       "0            1.02                    0.32                 0.09   \n",
       "1            1.02                    0.36                 1.05   \n",
       "2            1.02                    0.18                 0.30   \n",
       "3            1.02                    0.58                 0.00   \n",
       "4            1.02                    0.65                 0.14   \n",
       "\n",
       "   BASEL_sunshine  BASEL_temp_mean  BASEL_temp_min  BASEL_temp_max  \\\n",
       "0            0.70             6.50            0.80           10.90   \n",
       "1            1.10             6.10            3.30           10.10   \n",
       "2            0.00             8.50            5.10            9.90   \n",
       "3            4.10             6.30            3.80           10.60   \n",
       "4            5.40             3.00           -0.70            6.00   \n",
       "\n",
       "   BELGRADE_cloud_cover  BELGRADE_humidity  BELGRADE_pressure  \\\n",
       "0                     1               0.81               1.02   \n",
       "1                     6               0.84               1.02   \n",
       "2                     6               0.77               1.02   \n",
       "3                     8               0.93               1.03   \n",
       "4                     8               0.99               1.03   \n",
       "\n",
       "   BELGRADE_global_radiation  BELGRADE_precipitation  BELGRADE_sunshine  \\\n",
       "0                       0.88                    0.00               7.00   \n",
       "1                       0.25                    0.00               0.00   \n",
       "2                       0.67                    0.00               3.50   \n",
       "3                       0.25                    0.00               0.00   \n",
       "4                       0.25                    0.06               0.00   \n",
       "\n",
       "   BELGRADE_temp_mean  BELGRADE_temp_min  BELGRADE_temp_max  \\\n",
       "0                3.70              -0.90               7.90   \n",
       "1                2.90               2.20               4.40   \n",
       "2                3.10              -0.50               6.40   \n",
       "3                2.00              -2.00               3.00   \n",
       "4                2.00               0.70               2.80   \n",
       "\n",
       "   BUDAPEST_cloud_cover  BUDAPEST_humidity  BUDAPEST_pressure  \\\n",
       "0                     4               0.67               1.02   \n",
       "1                     4               0.67               1.02   \n",
       "2                     4               0.67               1.02   \n",
       "3                     4               0.67               1.02   \n",
       "4                     4               0.67               1.02   \n",
       "\n",
       "   BUDAPEST_global_radiation  BUDAPEST_precipitation  BUDAPEST_sunshine  \\\n",
       "0                       0.44                    0.01               2.30   \n",
       "1                       0.18                    0.31               0.00   \n",
       "2                       0.30                    0.00               0.60   \n",
       "3                       0.19                    0.00               0.00   \n",
       "4                       0.19                    0.00               0.00   \n",
       "\n",
       "   BUDAPEST_temp_mean  BUDAPEST_temp_min  BUDAPEST_temp_max  \\\n",
       "0                2.40              -0.40               5.10   \n",
       "1                2.30               1.40               3.10   \n",
       "2                2.70               1.70               5.30   \n",
       "3                2.00               0.40               4.40   \n",
       "4                2.50               1.10               5.30   \n",
       "\n",
       "   DEBILT_cloud_cover  DEBILT_humidity  DEBILT_pressure  \\\n",
       "0                   7             0.85             1.00   \n",
       "1                   8             0.90             1.01   \n",
       "2                   6             0.92             1.02   \n",
       "3                   8             0.95             1.03   \n",
       "4                   6             0.90             1.02   \n",
       "\n",
       "   DEBILT_global_radiation  DEBILT_precipitation  DEBILT_sunshine  \\\n",
       "0                     0.07                  0.25             0.00   \n",
       "1                     0.14                  0.06             0.10   \n",
       "2                     0.28                  0.01             3.00   \n",
       "3                     0.08                  0.09             0.00   \n",
       "4                     0.04                  0.39             0.00   \n",
       "\n",
       "   DEBILT_temp_mean  DEBILT_temp_min  DEBILT_temp_max  DUSSELDORF_cloud_cover  \\\n",
       "0              9.30             7.40            11.00                       8   \n",
       "1              7.70             6.40             8.30                       8   \n",
       "2              6.80             4.60             9.90                       7   \n",
       "3              6.70             3.60            10.10                       8   \n",
       "4              8.00             2.40            11.20                       7   \n",
       "\n",
       "   DUSSELDORF_humidity  DUSSELDORF_pressure  DUSSELDORF_global_radiation  \\\n",
       "0                 0.83                 1.02                         0.12   \n",
       "1                 0.89                 1.02                         0.18   \n",
       "2                 0.95                 1.02                         0.12   \n",
       "3                 0.86                 1.02                         0.12   \n",
       "4                 0.92                 1.02                         0.12   \n",
       "\n",
       "   DUSSELDORF_precipitation  DUSSELDORF_sunshine  DUSSELDORF_temp_mean  \\\n",
       "0                      0.08                 0.00                 10.00   \n",
       "1                      0.66                 0.50                  8.20   \n",
       "2                      0.07                 0.00                  7.10   \n",
       "3                      0.02                 0.00                  6.80   \n",
       "4                      0.62                 0.00                  7.70   \n",
       "\n",
       "   DUSSELDORF_temp_min  DUSSELDORF_temp_max  HEATHROW_cloud_cover  \\\n",
       "0                 7.00                11.50                     7   \n",
       "1                 7.40                11.00                     7   \n",
       "2                 6.90                 9.10                     8   \n",
       "3                 3.60                 8.00                     8   \n",
       "4                 6.20                11.00                     5   \n",
       "\n",
       "   HEATHROW_humidity  HEATHROW_pressure  HEATHROW_global_radiation  \\\n",
       "0               0.91               1.00                       0.13   \n",
       "1               0.98               1.01                       0.13   \n",
       "2               0.96               1.02                       0.15   \n",
       "3               0.98               1.02                       0.13   \n",
       "4               0.84               1.03                       0.30   \n",
       "\n",
       "   HEATHROW_precipitation  HEATHROW_sunshine  HEATHROW_temp_mean  \\\n",
       "0                    0.22               0.00               10.60   \n",
       "1                    0.23               0.00                6.10   \n",
       "2                    0.07               0.10                8.40   \n",
       "3                    0.00               0.00                9.40   \n",
       "4                    0.00               2.10                8.90   \n",
       "\n",
       "   HEATHROW_temp_min  HEATHROW_temp_max  KASSEL_humidity  KASSEL_pressure  \\\n",
       "0               9.40               8.30             0.82             1.01   \n",
       "1               3.90              10.60             0.86             1.01   \n",
       "2               6.10              12.20             0.91             1.01   \n",
       "3               6.70               8.90             0.87             1.03   \n",
       "4               8.90               7.20             0.86             1.03   \n",
       "\n",
       "   KASSEL_global_radiation  KASSEL_precipitation  KASSEL_sunshine  \\\n",
       "0                     0.28                  0.48             1.60   \n",
       "1                     0.12                  0.27             0.00   \n",
       "2                     0.12                  0.60             0.00   \n",
       "3                     0.12                  0.00             0.00   \n",
       "4                     0.13                  0.71             0.00   \n",
       "\n",
       "   KASSEL_temp_mean  KASSEL_temp_min  KASSEL_temp_max  LJUBLJANA_cloud_cover  \\\n",
       "0              7.90             3.90             9.40                      8   \n",
       "1              7.70             6.80             9.10                      6   \n",
       "2              6.50             6.00             8.00                      8   \n",
       "3              5.80             5.20             6.50                      6   \n",
       "4              5.40             3.70             6.00                      7   \n",
       "\n",
       "   LJUBLJANA_humidity  LJUBLJANA_pressure  LJUBLJANA_global_radiation  \\\n",
       "0                1.00                1.02                        0.20   \n",
       "1                0.94                1.02                        0.56   \n",
       "2                0.96                1.02                        0.20   \n",
       "3                0.94                1.02                        0.49   \n",
       "4                0.94                1.02                        0.20   \n",
       "\n",
       "   LJUBLJANA_precipitation  LJUBLJANA_sunshine  LJUBLJANA_temp_mean  \\\n",
       "0                     0.00                0.00                -0.60   \n",
       "1                     0.13                3.20                 2.10   \n",
       "2                     0.12                0.00                 4.60   \n",
       "3                     0.00                2.20                 3.20   \n",
       "4                     0.00                0.00                 3.60   \n",
       "\n",
       "   LJUBLJANA_temp_min  LJUBLJANA_temp_max  MAASTRICHT_cloud_cover  \\\n",
       "0               -1.90                0.50                       7   \n",
       "1               -1.30                5.50                       8   \n",
       "2                0.90                6.30                       7   \n",
       "3                1.00                7.00                       7   \n",
       "4                0.40                4.80                       7   \n",
       "\n",
       "   MAASTRICHT_humidity  MAASTRICHT_pressure  MAASTRICHT_global_radiation  \\\n",
       "0                 0.83                 1.01                         0.22   \n",
       "1                 0.92                 1.01                         0.17   \n",
       "2                 0.97                 1.02                         0.12   \n",
       "3                 0.89                 1.03                         0.16   \n",
       "4                 0.92                 1.03                         0.12   \n",
       "\n",
       "   MAASTRICHT_precipitation  MAASTRICHT_sunshine  MAASTRICHT_temp_mean  \\\n",
       "0                      0.32                 1.00                  9.50   \n",
       "1                      1.34                 0.40                  8.60   \n",
       "2                      0.46                 0.00                  6.90   \n",
       "3                      0.00                 0.30                  7.00   \n",
       "4                      0.56                 0.00                  8.10   \n",
       "\n",
       "   MAASTRICHT_temp_min  MAASTRICHT_temp_max  MADRID_cloud_cover  \\\n",
       "0                 8.50                11.10                   6   \n",
       "1                 7.50                 9.90                   7   \n",
       "2                 5.50                 9.90                   5   \n",
       "3                 3.00                10.00                   0   \n",
       "4                 2.50                11.10                   2   \n",
       "\n",
       "   MADRID_humidity  MADRID_pressure  MADRID_global_radiation  \\\n",
       "0             0.92             1.03                     0.53   \n",
       "1             0.86             1.03                     0.46   \n",
       "2             0.90             1.03                     0.63   \n",
       "3             0.75             1.03                     1.16   \n",
       "4             0.64             1.03                     1.10   \n",
       "\n",
       "   MADRID_precipitation  MADRID_sunshine  MADRID_temp_mean  MADRID_temp_min  \\\n",
       "0                  0.00             1.40              7.60             4.40   \n",
       "1                  0.00             0.90              9.80             7.40   \n",
       "2                  0.00             2.30              8.60             6.40   \n",
       "3                  0.00             8.70             10.30             4.50   \n",
       "4                  0.00             7.80             12.10             8.20   \n",
       "\n",
       "   MADRID_temp_max  MUNCHENB_cloud_cover  MUNCHENB_humidity  \\\n",
       "0            10.80                     5               0.67   \n",
       "1            12.20                     6               0.72   \n",
       "2            10.80                     6               0.91   \n",
       "3            16.10                     6               0.90   \n",
       "4            16.00                     5               0.85   \n",
       "\n",
       "   MUNCHENB_global_radiation  MUNCHENB_precipitation  MUNCHENB_sunshine  \\\n",
       "0                       0.20                    0.10               0.00   \n",
       "1                       0.61                    0.30               5.10   \n",
       "2                       0.20                    0.30               0.00   \n",
       "3                       0.20                    0.01               0.00   \n",
       "4                       0.65                    0.96               5.60   \n",
       "\n",
       "   MUNCHENB_temp_mean  MUNCHENB_temp_min  MUNCHENB_temp_max  OSLO_cloud_cover  \\\n",
       "0                6.90               1.10              10.40                 8   \n",
       "1                6.20               4.20              10.20                 8   \n",
       "2                5.80               4.00               8.00                 8   \n",
       "3                3.90               3.20               5.40                 8   \n",
       "4                1.80              -3.00               6.00                 8   \n",
       "\n",
       "   OSLO_humidity  OSLO_pressure  OSLO_global_radiation  OSLO_precipitation  \\\n",
       "0           0.98           1.00                   0.04                1.14   \n",
       "1           0.62           1.01                   0.04                0.00   \n",
       "2           0.69           1.02                   0.04                0.08   \n",
       "3           0.98           1.02                   0.04                0.35   \n",
       "4           0.96           1.01                   0.05                0.26   \n",
       "\n",
       "   OSLO_sunshine  OSLO_temp_mean  OSLO_temp_min  OSLO_temp_max  \\\n",
       "0           0.00            4.90           3.80           5.90   \n",
       "1           0.00            3.40           2.80           4.90   \n",
       "2           0.00            1.90           0.60           3.10   \n",
       "3           0.00            3.00           0.40           4.90   \n",
       "4           0.00            3.70           2.90           4.90   \n",
       "\n",
       "   SONNBLICK_cloud_cover  SONNBLICK_humidity  SONNBLICK_pressure  \\\n",
       "0                      4                0.73                1.03   \n",
       "1                      6                0.97                1.03   \n",
       "2                      8                0.93                1.03   \n",
       "3                      5                0.93                1.04   \n",
       "4                      2                0.75                1.04   \n",
       "\n",
       "   SONNBLICK_global_radiation  SONNBLICK_precipitation  SONNBLICK_sunshine  \\\n",
       "0                        0.48                     0.01                2.30   \n",
       "1                        0.21                     0.61                0.00   \n",
       "2                        0.21                     3.20                0.00   \n",
       "3                        0.22                     1.10                0.00   \n",
       "4                        0.72                     0.01                6.10   \n",
       "\n",
       "   SONNBLICK_temp_mean  SONNBLICK_temp_min  SONNBLICK_temp_max  \\\n",
       "0                -5.90               -8.50               -3.20   \n",
       "1                -9.50              -10.50               -8.50   \n",
       "2                -9.50              -10.00               -8.90   \n",
       "3               -11.50              -12.90              -10.00   \n",
       "4                -9.30              -12.00               -6.50   \n",
       "\n",
       "   STOCKHOLM_cloud_cover  STOCKHOLM_pressure  STOCKHOLM_global_radiation  \\\n",
       "0                      5                1.01                        0.05   \n",
       "1                      5                1.01                        0.05   \n",
       "2                      5                1.01                        0.05   \n",
       "3                      5                1.01                        0.05   \n",
       "4                      5                1.01                        0.05   \n",
       "\n",
       "   STOCKHOLM_precipitation  STOCKHOLM_sunshine  STOCKHOLM_temp_mean  \\\n",
       "0                     0.32                0.00                 4.20   \n",
       "1                     0.06                0.00                 4.00   \n",
       "2                     0.02                0.00                 2.40   \n",
       "3                     0.00                0.00                 1.20   \n",
       "4                     1.32                0.00                 3.30   \n",
       "\n",
       "   STOCKHOLM_temp_min  STOCKHOLM_temp_max  VALENTIA_cloud_cover  \\\n",
       "0                2.20                4.90                     5   \n",
       "1                3.00                5.00                     7   \n",
       "2                1.30                4.10                     7   \n",
       "3                0.40                2.30                     7   \n",
       "4                0.80                4.30                     3   \n",
       "\n",
       "   VALENTIA_humidity  VALENTIA_pressure  VALENTIA_global_radiation  \\\n",
       "0               0.88               1.00                       0.45   \n",
       "1               0.91               1.00                       0.25   \n",
       "2               0.91               1.01                       0.17   \n",
       "3               0.86               1.02                       0.13   \n",
       "4               0.80               1.03                       0.46   \n",
       "\n",
       "   VALENTIA_precipitation  VALENTIA_sunshine  VALENTIA_temp_mean  \\\n",
       "0                    0.34               4.70                8.50   \n",
       "1                    0.84               0.70                8.90   \n",
       "2                    0.08               0.10               10.50   \n",
       "3                    0.98               0.00                7.40   \n",
       "4                    0.00               5.70                5.70   \n",
       "\n",
       "   VALENTIA_temp_min  VALENTIA_temp_max  KASSEL_cloud_cover  \\\n",
       "0               6.00              10.90                   8   \n",
       "1               5.60              12.10                   6   \n",
       "2               8.10              12.90                   8   \n",
       "3               7.30              10.60                   6   \n",
       "4               3.00               8.40                   7   \n",
       "\n",
       "   MUNCHENB_pressure  STOCKHOLM_humidity  \n",
       "0               1.03                0.98  \n",
       "1               1.03                0.62  \n",
       "2               1.03                0.69  \n",
       "3               1.04                0.98  \n",
       "4               1.04                0.96  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "climate = pd.read_csv(os.path.join(path, '02 Data Sets', 'cleaned_climate.csv'))\n",
    "climate.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47822223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>BASEL_pleasant_weather</th>\n",
       "      <th>BELGRADE_pleasant_weather</th>\n",
       "      <th>BUDAPEST_pleasant_weather</th>\n",
       "      <th>DEBILT_pleasant_weather</th>\n",
       "      <th>DUSSELDORF_pleasant_weather</th>\n",
       "      <th>HEATHROW_pleasant_weather</th>\n",
       "      <th>KASSEL_pleasant_weather</th>\n",
       "      <th>LJUBLJANA_pleasant_weather</th>\n",
       "      <th>MAASTRICHT_pleasant_weather</th>\n",
       "      <th>MADRID_pleasant_weather</th>\n",
       "      <th>MUNCHENB_pleasant_weather</th>\n",
       "      <th>OSLO_pleasant_weather</th>\n",
       "      <th>SONNBLICK_pleasant_weather</th>\n",
       "      <th>STOCKHOLM_pleasant_weather</th>\n",
       "      <th>VALENTIA_pleasant_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19600101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19600102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19600103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19600104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19600105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE  BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
       "0  19600101                       0                          0   \n",
       "1  19600102                       0                          0   \n",
       "2  19600103                       0                          0   \n",
       "3  19600104                       0                          0   \n",
       "4  19600105                       0                          0   \n",
       "\n",
       "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "\n",
       "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   VALENTIA_pleasant_weather  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pleasant = pd.read_csv(os.path.join(path, '02 Data Sets', 'Dataset-Answers-Weather_Prediction_Pleasant_Weather.csv'))\n",
    "pleasant.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6540234",
   "metadata": {},
   "source": [
    "## 02. Preprocessing data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2138d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_cloud_cover</th>\n",
       "      <th>BASEL_humidity</th>\n",
       "      <th>BASEL_pressure</th>\n",
       "      <th>BASEL_global_radiation</th>\n",
       "      <th>BASEL_precipitation</th>\n",
       "      <th>BASEL_sunshine</th>\n",
       "      <th>BASEL_temp_mean</th>\n",
       "      <th>BASEL_temp_min</th>\n",
       "      <th>BASEL_temp_max</th>\n",
       "      <th>BELGRADE_cloud_cover</th>\n",
       "      <th>BELGRADE_humidity</th>\n",
       "      <th>BELGRADE_pressure</th>\n",
       "      <th>BELGRADE_global_radiation</th>\n",
       "      <th>BELGRADE_precipitation</th>\n",
       "      <th>BELGRADE_sunshine</th>\n",
       "      <th>BELGRADE_temp_mean</th>\n",
       "      <th>BELGRADE_temp_min</th>\n",
       "      <th>BELGRADE_temp_max</th>\n",
       "      <th>BUDAPEST_cloud_cover</th>\n",
       "      <th>BUDAPEST_humidity</th>\n",
       "      <th>BUDAPEST_pressure</th>\n",
       "      <th>BUDAPEST_global_radiation</th>\n",
       "      <th>BUDAPEST_precipitation</th>\n",
       "      <th>BUDAPEST_sunshine</th>\n",
       "      <th>BUDAPEST_temp_mean</th>\n",
       "      <th>BUDAPEST_temp_min</th>\n",
       "      <th>BUDAPEST_temp_max</th>\n",
       "      <th>DEBILT_cloud_cover</th>\n",
       "      <th>DEBILT_humidity</th>\n",
       "      <th>DEBILT_pressure</th>\n",
       "      <th>DEBILT_global_radiation</th>\n",
       "      <th>DEBILT_precipitation</th>\n",
       "      <th>DEBILT_sunshine</th>\n",
       "      <th>DEBILT_temp_mean</th>\n",
       "      <th>DEBILT_temp_min</th>\n",
       "      <th>DEBILT_temp_max</th>\n",
       "      <th>DUSSELDORF_cloud_cover</th>\n",
       "      <th>DUSSELDORF_humidity</th>\n",
       "      <th>DUSSELDORF_pressure</th>\n",
       "      <th>DUSSELDORF_global_radiation</th>\n",
       "      <th>DUSSELDORF_precipitation</th>\n",
       "      <th>DUSSELDORF_sunshine</th>\n",
       "      <th>DUSSELDORF_temp_mean</th>\n",
       "      <th>DUSSELDORF_temp_min</th>\n",
       "      <th>DUSSELDORF_temp_max</th>\n",
       "      <th>HEATHROW_cloud_cover</th>\n",
       "      <th>HEATHROW_humidity</th>\n",
       "      <th>HEATHROW_pressure</th>\n",
       "      <th>HEATHROW_global_radiation</th>\n",
       "      <th>HEATHROW_precipitation</th>\n",
       "      <th>HEATHROW_sunshine</th>\n",
       "      <th>HEATHROW_temp_mean</th>\n",
       "      <th>HEATHROW_temp_min</th>\n",
       "      <th>HEATHROW_temp_max</th>\n",
       "      <th>KASSEL_humidity</th>\n",
       "      <th>KASSEL_pressure</th>\n",
       "      <th>KASSEL_global_radiation</th>\n",
       "      <th>KASSEL_precipitation</th>\n",
       "      <th>KASSEL_sunshine</th>\n",
       "      <th>KASSEL_temp_mean</th>\n",
       "      <th>KASSEL_temp_min</th>\n",
       "      <th>KASSEL_temp_max</th>\n",
       "      <th>LJUBLJANA_cloud_cover</th>\n",
       "      <th>LJUBLJANA_humidity</th>\n",
       "      <th>LJUBLJANA_pressure</th>\n",
       "      <th>LJUBLJANA_global_radiation</th>\n",
       "      <th>LJUBLJANA_precipitation</th>\n",
       "      <th>LJUBLJANA_sunshine</th>\n",
       "      <th>LJUBLJANA_temp_mean</th>\n",
       "      <th>LJUBLJANA_temp_min</th>\n",
       "      <th>LJUBLJANA_temp_max</th>\n",
       "      <th>MAASTRICHT_cloud_cover</th>\n",
       "      <th>MAASTRICHT_humidity</th>\n",
       "      <th>MAASTRICHT_pressure</th>\n",
       "      <th>MAASTRICHT_global_radiation</th>\n",
       "      <th>MAASTRICHT_precipitation</th>\n",
       "      <th>MAASTRICHT_sunshine</th>\n",
       "      <th>MAASTRICHT_temp_mean</th>\n",
       "      <th>MAASTRICHT_temp_min</th>\n",
       "      <th>MAASTRICHT_temp_max</th>\n",
       "      <th>MADRID_cloud_cover</th>\n",
       "      <th>MADRID_humidity</th>\n",
       "      <th>MADRID_pressure</th>\n",
       "      <th>MADRID_global_radiation</th>\n",
       "      <th>MADRID_precipitation</th>\n",
       "      <th>MADRID_sunshine</th>\n",
       "      <th>MADRID_temp_mean</th>\n",
       "      <th>MADRID_temp_min</th>\n",
       "      <th>MADRID_temp_max</th>\n",
       "      <th>MUNCHENB_cloud_cover</th>\n",
       "      <th>MUNCHENB_humidity</th>\n",
       "      <th>MUNCHENB_global_radiation</th>\n",
       "      <th>MUNCHENB_precipitation</th>\n",
       "      <th>MUNCHENB_sunshine</th>\n",
       "      <th>MUNCHENB_temp_mean</th>\n",
       "      <th>MUNCHENB_temp_min</th>\n",
       "      <th>MUNCHENB_temp_max</th>\n",
       "      <th>OSLO_cloud_cover</th>\n",
       "      <th>OSLO_humidity</th>\n",
       "      <th>OSLO_pressure</th>\n",
       "      <th>OSLO_global_radiation</th>\n",
       "      <th>OSLO_precipitation</th>\n",
       "      <th>OSLO_sunshine</th>\n",
       "      <th>OSLO_temp_mean</th>\n",
       "      <th>OSLO_temp_min</th>\n",
       "      <th>OSLO_temp_max</th>\n",
       "      <th>SONNBLICK_cloud_cover</th>\n",
       "      <th>SONNBLICK_humidity</th>\n",
       "      <th>SONNBLICK_pressure</th>\n",
       "      <th>SONNBLICK_global_radiation</th>\n",
       "      <th>SONNBLICK_precipitation</th>\n",
       "      <th>SONNBLICK_sunshine</th>\n",
       "      <th>SONNBLICK_temp_mean</th>\n",
       "      <th>SONNBLICK_temp_min</th>\n",
       "      <th>SONNBLICK_temp_max</th>\n",
       "      <th>STOCKHOLM_cloud_cover</th>\n",
       "      <th>STOCKHOLM_pressure</th>\n",
       "      <th>STOCKHOLM_global_radiation</th>\n",
       "      <th>STOCKHOLM_precipitation</th>\n",
       "      <th>STOCKHOLM_sunshine</th>\n",
       "      <th>STOCKHOLM_temp_mean</th>\n",
       "      <th>STOCKHOLM_temp_min</th>\n",
       "      <th>STOCKHOLM_temp_max</th>\n",
       "      <th>VALENTIA_cloud_cover</th>\n",
       "      <th>VALENTIA_humidity</th>\n",
       "      <th>VALENTIA_pressure</th>\n",
       "      <th>VALENTIA_global_radiation</th>\n",
       "      <th>VALENTIA_precipitation</th>\n",
       "      <th>VALENTIA_sunshine</th>\n",
       "      <th>VALENTIA_temp_mean</th>\n",
       "      <th>VALENTIA_temp_min</th>\n",
       "      <th>VALENTIA_temp_max</th>\n",
       "      <th>KASSEL_cloud_cover</th>\n",
       "      <th>MUNCHENB_pressure</th>\n",
       "      <th>STOCKHOLM_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.70</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>7.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.40</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>5.10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.30</td>\n",
       "      <td>7.40</td>\n",
       "      <td>11.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>9.40</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.90</td>\n",
       "      <td>3.90</td>\n",
       "      <td>9.40</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>8.50</td>\n",
       "      <td>11.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.60</td>\n",
       "      <td>4.40</td>\n",
       "      <td>10.80</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.90</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.90</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-5.90</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.70</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>10.90</td>\n",
       "      <td>8</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.10</td>\n",
       "      <td>6.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>10.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7.70</td>\n",
       "      <td>6.40</td>\n",
       "      <td>8.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.20</td>\n",
       "      <td>7.40</td>\n",
       "      <td>11.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>3.90</td>\n",
       "      <td>10.60</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.70</td>\n",
       "      <td>6.80</td>\n",
       "      <td>9.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.10</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>5.50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8.60</td>\n",
       "      <td>7.50</td>\n",
       "      <td>9.90</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9.80</td>\n",
       "      <td>7.40</td>\n",
       "      <td>12.20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.10</td>\n",
       "      <td>6.20</td>\n",
       "      <td>4.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.50</td>\n",
       "      <td>-10.50</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.90</td>\n",
       "      <td>5.60</td>\n",
       "      <td>12.10</td>\n",
       "      <td>6</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>5.10</td>\n",
       "      <td>9.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>6.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5.30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>4.60</td>\n",
       "      <td>9.90</td>\n",
       "      <td>7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.10</td>\n",
       "      <td>6.90</td>\n",
       "      <td>9.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8.40</td>\n",
       "      <td>6.10</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.90</td>\n",
       "      <td>5.50</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>8.60</td>\n",
       "      <td>6.40</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.50</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.50</td>\n",
       "      <td>8.10</td>\n",
       "      <td>12.90</td>\n",
       "      <td>8</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>3.80</td>\n",
       "      <td>10.60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>3.60</td>\n",
       "      <td>10.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6.70</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>5.20</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.70</td>\n",
       "      <td>10.30</td>\n",
       "      <td>4.50</td>\n",
       "      <td>16.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>-12.90</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.30</td>\n",
       "      <td>10.60</td>\n",
       "      <td>6</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>11.20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.70</td>\n",
       "      <td>6.20</td>\n",
       "      <td>11.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.90</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.70</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>11.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.80</td>\n",
       "      <td>12.10</td>\n",
       "      <td>8.20</td>\n",
       "      <td>16.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.10</td>\n",
       "      <td>-9.30</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.70</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>7</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22945</th>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.70</td>\n",
       "      <td>15.90</td>\n",
       "      <td>11.40</td>\n",
       "      <td>21.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.70</td>\n",
       "      <td>18.20</td>\n",
       "      <td>12.10</td>\n",
       "      <td>24.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.40</td>\n",
       "      <td>11.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>16.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.80</td>\n",
       "      <td>15.70</td>\n",
       "      <td>12.80</td>\n",
       "      <td>19.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.40</td>\n",
       "      <td>17.80</td>\n",
       "      <td>13.60</td>\n",
       "      <td>21.40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.90</td>\n",
       "      <td>16.40</td>\n",
       "      <td>11.90</td>\n",
       "      <td>18.90</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>13.10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>5.90</td>\n",
       "      <td>14.70</td>\n",
       "      <td>12.10</td>\n",
       "      <td>21.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.30</td>\n",
       "      <td>18.60</td>\n",
       "      <td>14.10</td>\n",
       "      <td>22.60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5.30</td>\n",
       "      <td>20.00</td>\n",
       "      <td>16.20</td>\n",
       "      <td>23.90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9.70</td>\n",
       "      <td>14.30</td>\n",
       "      <td>8.30</td>\n",
       "      <td>22.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.70</td>\n",
       "      <td>5.80</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>2.60</td>\n",
       "      <td>5</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.20</td>\n",
       "      <td>11.50</td>\n",
       "      <td>8.20</td>\n",
       "      <td>14.20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>13.50</td>\n",
       "      <td>4</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22946</th>\n",
       "      <td>6</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.40</td>\n",
       "      <td>16.70</td>\n",
       "      <td>14.30</td>\n",
       "      <td>21.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.70</td>\n",
       "      <td>15.90</td>\n",
       "      <td>10.60</td>\n",
       "      <td>21.20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.40</td>\n",
       "      <td>11.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>16.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.50</td>\n",
       "      <td>16.00</td>\n",
       "      <td>10.30</td>\n",
       "      <td>20.50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.90</td>\n",
       "      <td>19.40</td>\n",
       "      <td>15.40</td>\n",
       "      <td>23.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4.20</td>\n",
       "      <td>15.80</td>\n",
       "      <td>12.70</td>\n",
       "      <td>21.80</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>13.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4.50</td>\n",
       "      <td>12.90</td>\n",
       "      <td>9.80</td>\n",
       "      <td>19.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.00</td>\n",
       "      <td>18.90</td>\n",
       "      <td>15.80</td>\n",
       "      <td>23.50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.90</td>\n",
       "      <td>19.10</td>\n",
       "      <td>14.70</td>\n",
       "      <td>23.50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7.70</td>\n",
       "      <td>16.10</td>\n",
       "      <td>8.90</td>\n",
       "      <td>26.10</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.90</td>\n",
       "      <td>8.80</td>\n",
       "      <td>11.70</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>14.30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>13.50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22947</th>\n",
       "      <td>4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.10</td>\n",
       "      <td>16.70</td>\n",
       "      <td>13.10</td>\n",
       "      <td>22.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.70</td>\n",
       "      <td>13.40</td>\n",
       "      <td>8.60</td>\n",
       "      <td>18.20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.40</td>\n",
       "      <td>11.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>16.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.30</td>\n",
       "      <td>15.80</td>\n",
       "      <td>9.30</td>\n",
       "      <td>21.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.00</td>\n",
       "      <td>18.20</td>\n",
       "      <td>13.40</td>\n",
       "      <td>22.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4.20</td>\n",
       "      <td>16.50</td>\n",
       "      <td>11.20</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>13.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>5.10</td>\n",
       "      <td>13.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>20.70</td>\n",
       "      <td>8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>18.20</td>\n",
       "      <td>13.70</td>\n",
       "      <td>24.30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.12</td>\n",
       "      <td>8.10</td>\n",
       "      <td>19.00</td>\n",
       "      <td>15.40</td>\n",
       "      <td>22.60</td>\n",
       "      <td>7</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>6.80</td>\n",
       "      <td>17.40</td>\n",
       "      <td>11.20</td>\n",
       "      <td>26.20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6.80</td>\n",
       "      <td>9.70</td>\n",
       "      <td>7.70</td>\n",
       "      <td>14.20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.10</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>6.90</td>\n",
       "      <td>13.10</td>\n",
       "      <td>12.10</td>\n",
       "      <td>14.40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>13.50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22948</th>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.80</td>\n",
       "      <td>15.40</td>\n",
       "      <td>11.60</td>\n",
       "      <td>21.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.70</td>\n",
       "      <td>15.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>20.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.40</td>\n",
       "      <td>11.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>16.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.00</td>\n",
       "      <td>14.40</td>\n",
       "      <td>10.30</td>\n",
       "      <td>20.20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.90</td>\n",
       "      <td>16.70</td>\n",
       "      <td>11.90</td>\n",
       "      <td>21.10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.60</td>\n",
       "      <td>15.20</td>\n",
       "      <td>13.40</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>13.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>5.70</td>\n",
       "      <td>14.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>16.30</td>\n",
       "      <td>12.80</td>\n",
       "      <td>21.40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.10</td>\n",
       "      <td>15.70</td>\n",
       "      <td>13.10</td>\n",
       "      <td>18.30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.30</td>\n",
       "      <td>14.50</td>\n",
       "      <td>9.20</td>\n",
       "      <td>23.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.90</td>\n",
       "      <td>5.90</td>\n",
       "      <td>2.10</td>\n",
       "      <td>8.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.40</td>\n",
       "      <td>7.50</td>\n",
       "      <td>5.10</td>\n",
       "      <td>12.40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>13.50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22949</th>\n",
       "      <td>5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.20</td>\n",
       "      <td>13.50</td>\n",
       "      <td>9.90</td>\n",
       "      <td>19.20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.70</td>\n",
       "      <td>14.40</td>\n",
       "      <td>10.40</td>\n",
       "      <td>18.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.40</td>\n",
       "      <td>11.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>16.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.70</td>\n",
       "      <td>12.80</td>\n",
       "      <td>6.70</td>\n",
       "      <td>16.20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.70</td>\n",
       "      <td>15.20</td>\n",
       "      <td>9.70</td>\n",
       "      <td>19.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.70</td>\n",
       "      <td>13.70</td>\n",
       "      <td>9.80</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5.40</td>\n",
       "      <td>13.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>6.30</td>\n",
       "      <td>13.60</td>\n",
       "      <td>8.80</td>\n",
       "      <td>23.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.30</td>\n",
       "      <td>11.00</td>\n",
       "      <td>19.40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.10</td>\n",
       "      <td>12.10</td>\n",
       "      <td>16.10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>6.80</td>\n",
       "      <td>12.90</td>\n",
       "      <td>7.90</td>\n",
       "      <td>19.60</td>\n",
       "      <td>6</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.90</td>\n",
       "      <td>9.20</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.70</td>\n",
       "      <td>5</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.70</td>\n",
       "      <td>5.00</td>\n",
       "      <td>12.60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.70</td>\n",
       "      <td>7.90</td>\n",
       "      <td>13.50</td>\n",
       "      <td>3</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22950 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BASEL_cloud_cover  BASEL_humidity  BASEL_pressure  \\\n",
       "0                      7            0.85            1.02   \n",
       "1                      6            0.84            1.02   \n",
       "2                      8            0.90            1.02   \n",
       "3                      3            0.92            1.02   \n",
       "4                      6            0.95            1.02   \n",
       "...                  ...             ...             ...   \n",
       "22945                  1            0.79            1.02   \n",
       "22946                  6            0.77            1.02   \n",
       "22947                  4            0.76            1.02   \n",
       "22948                  5            0.80            1.02   \n",
       "22949                  5            0.84            1.02   \n",
       "\n",
       "       BASEL_global_radiation  BASEL_precipitation  BASEL_sunshine  \\\n",
       "0                        0.32                 0.09            0.70   \n",
       "1                        0.36                 1.05            1.10   \n",
       "2                        0.18                 0.30            0.00   \n",
       "3                        0.58                 0.00            4.10   \n",
       "4                        0.65                 0.14            5.40   \n",
       "...                       ...                  ...             ...   \n",
       "22945                    1.34                 0.22            7.70   \n",
       "22946                    1.34                 0.22            5.40   \n",
       "22947                    1.34                 0.22            6.10   \n",
       "22948                    1.34                 0.22            5.80   \n",
       "22949                    1.34                 0.22            3.20   \n",
       "\n",
       "       BASEL_temp_mean  BASEL_temp_min  BASEL_temp_max  BELGRADE_cloud_cover  \\\n",
       "0                 6.50            0.80           10.90                     1   \n",
       "1                 6.10            3.30           10.10                     6   \n",
       "2                 8.50            5.10            9.90                     6   \n",
       "3                 6.30            3.80           10.60                     8   \n",
       "4                 3.00           -0.70            6.00                     8   \n",
       "...                ...             ...             ...                   ...   \n",
       "22945            15.90           11.40           21.40                     2   \n",
       "22946            16.70           14.30           21.90                     0   \n",
       "22947            16.70           13.10           22.40                     2   \n",
       "22948            15.40           11.60           21.10                     1   \n",
       "22949            13.50            9.90           19.20                     4   \n",
       "\n",
       "       BELGRADE_humidity  BELGRADE_pressure  BELGRADE_global_radiation  \\\n",
       "0                   0.81               1.02                       0.88   \n",
       "1                   0.84               1.02                       0.25   \n",
       "2                   0.77               1.02                       0.67   \n",
       "3                   0.93               1.03                       0.25   \n",
       "4                   0.99               1.03                       0.25   \n",
       "...                  ...                ...                        ...   \n",
       "22945               0.68               1.03                       1.57   \n",
       "22946               0.68               1.03                       1.57   \n",
       "22947               0.68               1.03                       1.57   \n",
       "22948               0.68               1.02                       1.57   \n",
       "22949               0.68               1.02                       1.57   \n",
       "\n",
       "       BELGRADE_precipitation  BELGRADE_sunshine  BELGRADE_temp_mean  \\\n",
       "0                        0.00               7.00                3.70   \n",
       "1                        0.00               0.00                2.90   \n",
       "2                        0.00               3.50                3.10   \n",
       "3                        0.00               0.00                2.00   \n",
       "4                        0.06               0.00                2.00   \n",
       "...                       ...                ...                 ...   \n",
       "22945                    0.18               5.70               18.20   \n",
       "22946                    0.18               5.70               15.90   \n",
       "22947                    0.18               5.70               13.40   \n",
       "22948                    0.18               5.70               15.00   \n",
       "22949                    0.18               5.70               14.40   \n",
       "\n",
       "       BELGRADE_temp_min  BELGRADE_temp_max  BUDAPEST_cloud_cover  \\\n",
       "0                  -0.90               7.90                     4   \n",
       "1                   2.20               4.40                     4   \n",
       "2                  -0.50               6.40                     4   \n",
       "3                  -2.00               3.00                     4   \n",
       "4                   0.70               2.80                     4   \n",
       "...                  ...                ...                   ...   \n",
       "22945              12.10              24.40                     4   \n",
       "22946              10.60              21.20                     4   \n",
       "22947               8.60              18.20                     4   \n",
       "22948               9.10              20.90                     4   \n",
       "22949              10.40              18.40                     4   \n",
       "\n",
       "       BUDAPEST_humidity  BUDAPEST_pressure  BUDAPEST_global_radiation  \\\n",
       "0                   0.67               1.02                       0.44   \n",
       "1                   0.67               1.02                       0.18   \n",
       "2                   0.67               1.02                       0.30   \n",
       "3                   0.67               1.02                       0.19   \n",
       "4                   0.67               1.02                       0.19   \n",
       "...                  ...                ...                        ...   \n",
       "22945               0.67               1.02                       1.41   \n",
       "22946               0.67               1.02                       1.41   \n",
       "22947               0.67               1.02                       1.41   \n",
       "22948               0.67               1.02                       1.41   \n",
       "22949               0.67               1.02                       1.41   \n",
       "\n",
       "       BUDAPEST_precipitation  BUDAPEST_sunshine  BUDAPEST_temp_mean  \\\n",
       "0                        0.01               2.30                2.40   \n",
       "1                        0.31               0.00                2.30   \n",
       "2                        0.00               0.60                2.70   \n",
       "3                        0.00               0.00                2.00   \n",
       "4                        0.00               0.00                2.50   \n",
       "...                       ...                ...                 ...   \n",
       "22945                    0.14               5.40               11.70   \n",
       "22946                    0.14               5.40               11.70   \n",
       "22947                    0.14               5.40               11.70   \n",
       "22948                    0.14               5.40               11.70   \n",
       "22949                    0.14               5.40               11.70   \n",
       "\n",
       "       BUDAPEST_temp_min  BUDAPEST_temp_max  DEBILT_cloud_cover  \\\n",
       "0                  -0.40               5.10                   7   \n",
       "1                   1.40               3.10                   8   \n",
       "2                   1.70               5.30                   6   \n",
       "3                   0.40               4.40                   8   \n",
       "4                   1.10               5.30                   6   \n",
       "...                  ...                ...                 ...   \n",
       "22945               7.90              16.20                   8   \n",
       "22946               7.90              16.20                   8   \n",
       "22947               7.90              16.20                   8   \n",
       "22948               7.90              16.20                   8   \n",
       "22949               7.90              16.20                   8   \n",
       "\n",
       "       DEBILT_humidity  DEBILT_pressure  DEBILT_global_radiation  \\\n",
       "0                 0.85             1.00                     0.07   \n",
       "1                 0.90             1.01                     0.14   \n",
       "2                 0.92             1.02                     0.28   \n",
       "3                 0.95             1.03                     0.08   \n",
       "4                 0.90             1.02                     0.04   \n",
       "...                ...              ...                      ...   \n",
       "22945             0.84             1.02                     1.13   \n",
       "22946             0.84             1.02                     1.13   \n",
       "22947             0.86             1.02                     1.13   \n",
       "22948             0.87             1.02                     1.13   \n",
       "22949             0.89             1.02                     1.13   \n",
       "\n",
       "       DEBILT_precipitation  DEBILT_sunshine  DEBILT_temp_mean  \\\n",
       "0                      0.25             0.00              9.30   \n",
       "1                      0.06             0.10              7.70   \n",
       "2                      0.01             3.00              6.80   \n",
       "3                      0.09             0.00              6.70   \n",
       "4                      0.39             0.00              8.00   \n",
       "...                     ...              ...               ...   \n",
       "22945                  0.22             2.80             15.70   \n",
       "22946                  0.22             3.50             16.00   \n",
       "22947                  0.22             3.30             15.80   \n",
       "22948                  0.22             6.00             14.40   \n",
       "22949                  0.22             0.70             12.80   \n",
       "\n",
       "       DEBILT_temp_min  DEBILT_temp_max  DUSSELDORF_cloud_cover  \\\n",
       "0                 7.40            11.00                       8   \n",
       "1                 6.40             8.30                       8   \n",
       "2                 4.60             9.90                       7   \n",
       "3                 3.60            10.10                       8   \n",
       "4                 2.40            11.20                       7   \n",
       "...                ...              ...                     ...   \n",
       "22945            12.80            19.40                       8   \n",
       "22946            10.30            20.50                       7   \n",
       "22947             9.30            21.10                       8   \n",
       "22948            10.30            20.20                       7   \n",
       "22949             6.70            16.20                       8   \n",
       "\n",
       "       DUSSELDORF_humidity  DUSSELDORF_pressure  DUSSELDORF_global_radiation  \\\n",
       "0                     0.83                 1.02                         0.12   \n",
       "1                     0.89                 1.02                         0.18   \n",
       "2                     0.95                 1.02                         0.12   \n",
       "3                     0.86                 1.02                         0.12   \n",
       "4                     0.92                 1.02                         0.12   \n",
       "...                    ...                  ...                          ...   \n",
       "22945                 0.75                 1.02                         1.13   \n",
       "22946                 0.71                 1.02                         1.13   \n",
       "22947                 0.73                 1.02                         1.13   \n",
       "22948                 0.73                 1.02                         1.13   \n",
       "22949                 0.78                 1.02                         1.13   \n",
       "\n",
       "       DUSSELDORF_precipitation  DUSSELDORF_sunshine  DUSSELDORF_temp_mean  \\\n",
       "0                          0.08                 0.00                 10.00   \n",
       "1                          0.66                 0.50                  8.20   \n",
       "2                          0.07                 0.00                  7.10   \n",
       "3                          0.02                 0.00                  6.80   \n",
       "4                          0.62                 0.00                  7.70   \n",
       "...                         ...                  ...                   ...   \n",
       "22945                      0.20                 6.40                 17.80   \n",
       "22946                      0.20                 4.90                 19.40   \n",
       "22947                      0.20                 4.00                 18.20   \n",
       "22948                      0.20                 6.90                 16.70   \n",
       "22949                      0.20                 1.70                 15.20   \n",
       "\n",
       "       DUSSELDORF_temp_min  DUSSELDORF_temp_max  HEATHROW_cloud_cover  \\\n",
       "0                     7.00                11.50                     7   \n",
       "1                     7.40                11.00                     7   \n",
       "2                     6.90                 9.10                     8   \n",
       "3                     3.60                 8.00                     8   \n",
       "4                     6.20                11.00                     5   \n",
       "...                    ...                  ...                   ...   \n",
       "22945                13.60                21.40                     5   \n",
       "22946                15.40                23.90                     4   \n",
       "22947                13.40                22.00                     7   \n",
       "22948                11.90                21.10                     5   \n",
       "22949                 9.70                19.50                     5   \n",
       "\n",
       "       HEATHROW_humidity  HEATHROW_pressure  HEATHROW_global_radiation  \\\n",
       "0                   0.91               1.00                       0.13   \n",
       "1                   0.98               1.01                       0.13   \n",
       "2                   0.96               1.02                       0.15   \n",
       "3                   0.98               1.02                       0.13   \n",
       "4                   0.84               1.03                       0.30   \n",
       "...                  ...                ...                        ...   \n",
       "22945               0.87               1.01                       1.18   \n",
       "22946               0.82               1.02                       1.18   \n",
       "22947               0.85               1.01                       1.18   \n",
       "22948               0.86               1.01                       1.18   \n",
       "22949               0.89               1.01                       1.18   \n",
       "\n",
       "       HEATHROW_precipitation  HEATHROW_sunshine  HEATHROW_temp_mean  \\\n",
       "0                        0.22               0.00               10.60   \n",
       "1                        0.23               0.00                6.10   \n",
       "2                        0.07               0.10                8.40   \n",
       "3                        0.00               0.00                9.40   \n",
       "4                        0.00               2.10                8.90   \n",
       "...                       ...                ...                 ...   \n",
       "22945                    0.16               1.90               16.40   \n",
       "22946                    0.16               4.20               15.80   \n",
       "22947                    0.16               4.20               16.50   \n",
       "22948                    0.16               0.60               15.20   \n",
       "22949                    0.16               3.70               13.70   \n",
       "\n",
       "       HEATHROW_temp_min  HEATHROW_temp_max  KASSEL_humidity  KASSEL_pressure  \\\n",
       "0                   9.40               8.30             0.82             1.01   \n",
       "1                   3.90              10.60             0.86             1.01   \n",
       "2                   6.10              12.20             0.91             1.01   \n",
       "3                   6.70               8.90             0.87             1.03   \n",
       "4                   8.90               7.20             0.86             1.03   \n",
       "...                  ...                ...              ...              ...   \n",
       "22945              11.90              18.90             0.77             1.02   \n",
       "22946              12.70              21.80             0.77             1.02   \n",
       "22947              11.20              17.00             0.77             1.02   \n",
       "22948              13.40              17.50             0.77             1.02   \n",
       "22949               9.80              17.60             0.77             1.02   \n",
       "\n",
       "       KASSEL_global_radiation  KASSEL_precipitation  KASSEL_sunshine  \\\n",
       "0                         0.28                  0.48             1.60   \n",
       "1                         0.12                  0.27             0.00   \n",
       "2                         0.12                  0.60             0.00   \n",
       "3                         0.12                  0.00             0.00   \n",
       "4                         0.13                  0.71             0.00   \n",
       "...                        ...                   ...              ...   \n",
       "22945                     1.14                  0.19             4.00   \n",
       "22946                     1.14                  0.19             4.00   \n",
       "22947                     1.14                  0.19             4.00   \n",
       "22948                     1.14                  0.19             4.00   \n",
       "22949                     1.14                  0.19             4.00   \n",
       "\n",
       "       KASSEL_temp_mean  KASSEL_temp_min  KASSEL_temp_max  \\\n",
       "0                  7.90             3.90             9.40   \n",
       "1                  7.70             6.80             9.10   \n",
       "2                  6.50             6.00             8.00   \n",
       "3                  5.80             5.20             6.50   \n",
       "4                  5.40             3.70             6.00   \n",
       "...                 ...              ...              ...   \n",
       "22945              9.10             5.40            13.10   \n",
       "22946              9.10             5.40            13.10   \n",
       "22947              9.10             5.40            13.10   \n",
       "22948              9.10             5.40            13.10   \n",
       "22949              9.10             5.40            13.10   \n",
       "\n",
       "       LJUBLJANA_cloud_cover  LJUBLJANA_humidity  LJUBLJANA_pressure  \\\n",
       "0                          8                1.00                1.02   \n",
       "1                          6                0.94                1.02   \n",
       "2                          8                0.96                1.02   \n",
       "3                          6                0.94                1.02   \n",
       "4                          7                0.94                1.02   \n",
       "...                      ...                 ...                 ...   \n",
       "22945                      4                0.80                1.03   \n",
       "22946                      3                0.82                1.03   \n",
       "22947                      3                0.81                1.03   \n",
       "22948                      3                0.77                1.02   \n",
       "22949                      3                0.77                1.01   \n",
       "\n",
       "       LJUBLJANA_global_radiation  LJUBLJANA_precipitation  \\\n",
       "0                            0.20                     0.00   \n",
       "1                            0.56                     0.13   \n",
       "2                            0.20                     0.12   \n",
       "3                            0.49                     0.00   \n",
       "4                            0.20                     0.00   \n",
       "...                           ...                      ...   \n",
       "22945                        1.35                     0.37   \n",
       "22946                        1.35                     0.37   \n",
       "22947                        1.35                     0.37   \n",
       "22948                        1.35                     0.37   \n",
       "22949                        1.35                     0.37   \n",
       "\n",
       "       LJUBLJANA_sunshine  LJUBLJANA_temp_mean  LJUBLJANA_temp_min  \\\n",
       "0                    0.00                -0.60               -1.90   \n",
       "1                    3.20                 2.10               -1.30   \n",
       "2                    0.00                 4.60                0.90   \n",
       "3                    2.20                 3.20                1.00   \n",
       "4                    0.00                 3.60                0.40   \n",
       "...                   ...                  ...                 ...   \n",
       "22945                5.90                14.70               12.10   \n",
       "22946                4.50                12.90                9.80   \n",
       "22947                5.10                13.20               10.20   \n",
       "22948                5.70                14.00               10.00   \n",
       "22949                6.30                13.60                8.80   \n",
       "\n",
       "       LJUBLJANA_temp_max  MAASTRICHT_cloud_cover  MAASTRICHT_humidity  \\\n",
       "0                    0.50                       7                 0.83   \n",
       "1                    5.50                       8                 0.92   \n",
       "2                    6.30                       7                 0.97   \n",
       "3                    7.00                       7                 0.89   \n",
       "4                    4.80                       7                 0.92   \n",
       "...                   ...                     ...                  ...   \n",
       "22945               21.10                       8                 0.67   \n",
       "22946               19.80                       7                 0.70   \n",
       "22947               20.70                       8                 0.69   \n",
       "22948               23.10                       8                 0.73   \n",
       "22949               23.40                       8                 0.80   \n",
       "\n",
       "       MAASTRICHT_pressure  MAASTRICHT_global_radiation  \\\n",
       "0                     1.01                         0.22   \n",
       "1                     1.01                         0.17   \n",
       "2                     1.02                         0.12   \n",
       "3                     1.03                         0.16   \n",
       "4                     1.03                         0.12   \n",
       "...                    ...                          ...   \n",
       "22945                 1.02                         1.17   \n",
       "22946                 1.02                         1.17   \n",
       "22947                 1.02                         1.17   \n",
       "22948                 1.02                         1.17   \n",
       "22949                 1.02                         1.17   \n",
       "\n",
       "       MAASTRICHT_precipitation  MAASTRICHT_sunshine  MAASTRICHT_temp_mean  \\\n",
       "0                          0.32                 1.00                  9.50   \n",
       "1                          1.34                 0.40                  8.60   \n",
       "2                          0.46                 0.00                  6.90   \n",
       "3                          0.00                 0.30                  7.00   \n",
       "4                          0.56                 0.00                  8.10   \n",
       "...                         ...                  ...                   ...   \n",
       "22945                      0.20                 5.30                 18.60   \n",
       "22946                      0.20                 5.00                 18.90   \n",
       "22947                      0.20                 3.20                 18.20   \n",
       "22948                      0.20                 6.80                 16.30   \n",
       "22949                      0.20                 3.00                 15.30   \n",
       "\n",
       "       MAASTRICHT_temp_min  MAASTRICHT_temp_max  MADRID_cloud_cover  \\\n",
       "0                     8.50                11.10                   6   \n",
       "1                     7.50                 9.90                   7   \n",
       "2                     5.50                 9.90                   5   \n",
       "3                     3.00                10.00                   0   \n",
       "4                     2.50                11.10                   2   \n",
       "...                    ...                  ...                 ...   \n",
       "22945                14.10                22.60                   8   \n",
       "22946                15.80                23.50                   8   \n",
       "22947                13.70                24.30                   8   \n",
       "22948                12.80                21.40                   5   \n",
       "22949                11.00                19.40                   8   \n",
       "\n",
       "       MADRID_humidity  MADRID_pressure  MADRID_global_radiation  \\\n",
       "0                 0.92             1.03                     0.53   \n",
       "1                 0.86             1.03                     0.46   \n",
       "2                 0.90             1.03                     0.63   \n",
       "3                 0.75             1.03                     1.16   \n",
       "4                 0.64             1.03                     1.10   \n",
       "...                ...              ...                      ...   \n",
       "22945             0.52             1.02                     1.89   \n",
       "22946             0.51             1.02                     1.89   \n",
       "22947             0.46             1.02                     1.89   \n",
       "22948             0.66             1.02                     1.89   \n",
       "22949             0.82             1.02                     1.89   \n",
       "\n",
       "       MADRID_precipitation  MADRID_sunshine  MADRID_temp_mean  \\\n",
       "0                      0.00             1.40              7.60   \n",
       "1                      0.00             0.90              9.80   \n",
       "2                      0.00             2.30              8.60   \n",
       "3                      0.00             8.70             10.30   \n",
       "4                      0.00             7.80             12.10   \n",
       "...                     ...              ...               ...   \n",
       "22945                  0.12             5.30             20.00   \n",
       "22946                  0.12             3.90             19.10   \n",
       "22947                  0.12             8.10             19.00   \n",
       "22948                  0.12             3.10             15.70   \n",
       "22949                  0.12             0.00             14.10   \n",
       "\n",
       "       MADRID_temp_min  MADRID_temp_max  MUNCHENB_cloud_cover  \\\n",
       "0                 4.40            10.80                     5   \n",
       "1                 7.40            12.20                     6   \n",
       "2                 6.40            10.80                     6   \n",
       "3                 4.50            16.10                     6   \n",
       "4                 8.20            16.00                     5   \n",
       "...                ...              ...                   ...   \n",
       "22945            16.20            23.90                     2   \n",
       "22946            14.70            23.50                     6   \n",
       "22947            15.40            22.60                     7   \n",
       "22948            13.10            18.30                     6   \n",
       "22949            12.10            16.10                     5   \n",
       "\n",
       "       MUNCHENB_humidity  MUNCHENB_global_radiation  MUNCHENB_precipitation  \\\n",
       "0                   0.67                       0.20                    0.10   \n",
       "1                   0.72                       0.61                    0.30   \n",
       "2                   0.91                       0.20                    0.30   \n",
       "3                   0.90                       0.20                    0.01   \n",
       "4                   0.85                       0.65                    0.96   \n",
       "...                  ...                        ...                     ...   \n",
       "22945               0.76                       1.37                    0.26   \n",
       "22946               0.70                       1.37                    0.26   \n",
       "22947               0.64                       1.37                    0.26   \n",
       "22948               0.75                       1.37                    0.26   \n",
       "22949               0.83                       1.37                    0.26   \n",
       "\n",
       "       MUNCHENB_sunshine  MUNCHENB_temp_mean  MUNCHENB_temp_min  \\\n",
       "0                   0.00                6.90               1.10   \n",
       "1                   5.10                6.20               4.20   \n",
       "2                   0.00                5.80               4.00   \n",
       "3                   0.00                3.90               3.20   \n",
       "4                   5.60                1.80              -3.00   \n",
       "...                  ...                 ...                ...   \n",
       "22945               9.70               14.30               8.30   \n",
       "22946               7.70               16.10               8.90   \n",
       "22947               6.80               17.40              11.20   \n",
       "22948               8.30               14.50               9.20   \n",
       "22949               6.80               12.90               7.90   \n",
       "\n",
       "       MUNCHENB_temp_max  OSLO_cloud_cover  OSLO_humidity  OSLO_pressure  \\\n",
       "0                  10.40                 8           0.98           1.00   \n",
       "1                  10.20                 8           0.62           1.01   \n",
       "2                   8.00                 8           0.69           1.02   \n",
       "3                   5.40                 8           0.98           1.02   \n",
       "4                   6.00                 8           0.96           1.01   \n",
       "...                  ...               ...            ...            ...   \n",
       "22945              22.20                 8           0.98           1.01   \n",
       "22946              26.10                 8           1.00           1.01   \n",
       "22947              26.20                 3           0.85           1.01   \n",
       "22948              23.50                 5           0.94           1.01   \n",
       "22949              19.60                 6           0.97           1.01   \n",
       "\n",
       "       OSLO_global_radiation  OSLO_precipitation  OSLO_sunshine  \\\n",
       "0                       0.04                1.14           0.00   \n",
       "1                       0.04                0.00           0.00   \n",
       "2                       0.04                0.08           0.00   \n",
       "3                       0.04                0.35           0.00   \n",
       "4                       0.05                0.26           0.00   \n",
       "...                      ...                 ...            ...   \n",
       "22945                   1.06                0.21           0.10   \n",
       "22946                   1.06                0.21           0.00   \n",
       "22947                   1.06                0.21           6.80   \n",
       "22948                   1.06                0.21           2.90   \n",
       "22949                   1.06                0.21           1.90   \n",
       "\n",
       "       OSLO_temp_mean  OSLO_temp_min  OSLO_temp_max  SONNBLICK_cloud_cover  \\\n",
       "0                4.90           3.80           5.90                      4   \n",
       "1                3.40           2.80           4.90                      6   \n",
       "2                1.90           0.60           3.10                      8   \n",
       "3                3.00           0.40           4.90                      5   \n",
       "4                3.70           2.90           4.90                      2   \n",
       "...               ...            ...            ...                    ...   \n",
       "22945            9.70           5.80          12.00                      2   \n",
       "22946           10.90           8.80          11.70                      5   \n",
       "22947            9.70           7.70          14.20                      3   \n",
       "22948            5.90           2.10           8.10                      3   \n",
       "22949            9.20           7.50          13.30                      4   \n",
       "\n",
       "       SONNBLICK_humidity  SONNBLICK_pressure  SONNBLICK_global_radiation  \\\n",
       "0                    0.73                1.03                        0.48   \n",
       "1                    0.97                1.03                        0.21   \n",
       "2                    0.93                1.03                        0.21   \n",
       "3                    0.93                1.04                        0.22   \n",
       "4                    0.75                1.04                        0.72   \n",
       "...                   ...                 ...                         ...   \n",
       "22945                0.84                1.03                        1.56   \n",
       "22946                0.84                1.03                        1.56   \n",
       "22947                0.84                1.03                        1.56   \n",
       "22948                0.84                1.03                        1.56   \n",
       "22949                0.84                1.03                        1.56   \n",
       "\n",
       "       SONNBLICK_precipitation  SONNBLICK_sunshine  SONNBLICK_temp_mean  \\\n",
       "0                         0.01                2.30                -5.90   \n",
       "1                         0.61                0.00                -9.50   \n",
       "2                         3.20                0.00                -9.50   \n",
       "3                         1.10                0.00               -11.50   \n",
       "4                         0.01                6.10                -9.30   \n",
       "...                        ...                 ...                  ...   \n",
       "22945                     0.47                4.70                 0.60   \n",
       "22946                     0.47                4.70                 2.30   \n",
       "22947                     0.47                4.70                 3.30   \n",
       "22948                     0.47                4.70                 3.40   \n",
       "22949                     0.47                4.70                 1.70   \n",
       "\n",
       "       SONNBLICK_temp_min  SONNBLICK_temp_max  STOCKHOLM_cloud_cover  \\\n",
       "0                   -8.50               -3.20                      5   \n",
       "1                  -10.50               -8.50                      5   \n",
       "2                  -10.00               -8.90                      5   \n",
       "3                  -12.90              -10.00                      5   \n",
       "4                  -12.00               -6.50                      5   \n",
       "...                   ...                 ...                    ...   \n",
       "22945               -1.40                2.60                      5   \n",
       "22946                0.60                4.00                      5   \n",
       "22947                2.10                4.50                      5   \n",
       "22948                2.70                4.10                      5   \n",
       "22949                0.70                2.70                      5   \n",
       "\n",
       "       STOCKHOLM_pressure  STOCKHOLM_global_radiation  \\\n",
       "0                    1.01                        0.05   \n",
       "1                    1.01                        0.05   \n",
       "2                    1.01                        0.05   \n",
       "3                    1.01                        0.05   \n",
       "4                    1.01                        0.05   \n",
       "...                   ...                         ...   \n",
       "22945                1.02                        1.11   \n",
       "22946                1.01                        1.11   \n",
       "22947                1.01                        1.11   \n",
       "22948                1.02                        1.11   \n",
       "22949                1.02                        1.11   \n",
       "\n",
       "       STOCKHOLM_precipitation  STOCKHOLM_sunshine  STOCKHOLM_temp_mean  \\\n",
       "0                         0.32                0.00                 4.20   \n",
       "1                         0.06                0.00                 4.00   \n",
       "2                         0.02                0.00                 2.40   \n",
       "3                         0.00                0.00                 1.20   \n",
       "4                         1.32                0.00                 3.30   \n",
       "...                        ...                 ...                  ...   \n",
       "22945                     0.14                3.20                11.50   \n",
       "22946                     0.14                0.80                12.50   \n",
       "22947                     0.14                6.90                13.10   \n",
       "22948                     0.14                8.40                 7.50   \n",
       "22949                     0.14                0.40                 9.70   \n",
       "\n",
       "       STOCKHOLM_temp_min  STOCKHOLM_temp_max  VALENTIA_cloud_cover  \\\n",
       "0                    2.20                4.90                     5   \n",
       "1                    3.00                5.00                     7   \n",
       "2                    1.30                4.10                     7   \n",
       "3                    0.40                2.30                     7   \n",
       "4                    0.80                4.30                     3   \n",
       "...                   ...                 ...                   ...   \n",
       "22945                8.20               14.20                     5   \n",
       "22946               11.00               14.30                     5   \n",
       "22947               12.10               14.40                     5   \n",
       "22948                5.10               12.40                     5   \n",
       "22949                5.00               12.60                     5   \n",
       "\n",
       "       VALENTIA_humidity  VALENTIA_pressure  VALENTIA_global_radiation  \\\n",
       "0                   0.88               1.00                       0.45   \n",
       "1                   0.91               1.00                       0.25   \n",
       "2                   0.91               1.01                       0.17   \n",
       "3                   0.86               1.02                       0.13   \n",
       "4                   0.80               1.03                       0.46   \n",
       "...                  ...                ...                        ...   \n",
       "22945               0.82               1.01                       1.13   \n",
       "22946               0.82               1.01                       1.13   \n",
       "22947               0.82               1.01                       1.13   \n",
       "22948               0.82               1.01                       1.13   \n",
       "22949               0.82               1.01                       1.13   \n",
       "\n",
       "       VALENTIA_precipitation  VALENTIA_sunshine  VALENTIA_temp_mean  \\\n",
       "0                        0.34               4.70                8.50   \n",
       "1                        0.84               0.70                8.90   \n",
       "2                        0.08               0.10               10.50   \n",
       "3                        0.98               0.00                7.40   \n",
       "4                        0.00               5.70                5.70   \n",
       "...                       ...                ...                 ...   \n",
       "22945                    0.41               3.40               10.70   \n",
       "22946                    0.41               3.40               10.70   \n",
       "22947                    0.41               3.40               10.70   \n",
       "22948                    0.41               3.40               10.70   \n",
       "22949                    0.41               3.40               10.70   \n",
       "\n",
       "       VALENTIA_temp_min  VALENTIA_temp_max  KASSEL_cloud_cover  \\\n",
       "0                   6.00              10.90                   8   \n",
       "1                   5.60              12.10                   6   \n",
       "2                   8.10              12.90                   8   \n",
       "3                   7.30              10.60                   6   \n",
       "4                   3.00               8.40                   7   \n",
       "...                  ...                ...                 ...   \n",
       "22945               7.90              13.50                   4   \n",
       "22946               7.90              13.50                   3   \n",
       "22947               7.90              13.50                   3   \n",
       "22948               7.90              13.50                   3   \n",
       "22949               7.90              13.50                   3   \n",
       "\n",
       "       MUNCHENB_pressure  STOCKHOLM_humidity  \n",
       "0                   1.03                0.98  \n",
       "1                   1.03                0.62  \n",
       "2                   1.03                0.69  \n",
       "3                   1.04                0.98  \n",
       "4                   1.04                0.96  \n",
       "...                  ...                 ...  \n",
       "22945               1.03                0.98  \n",
       "22946               1.03                1.00  \n",
       "22947               1.03                0.85  \n",
       "22948               1.03                0.94  \n",
       "22949               1.03                0.97  \n",
       "\n",
       "[22950 rows x 135 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the \"DATE , MONTH\" columsn\n",
    "df = climate.drop(columns = ['DATE','MONTH','Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5bfd31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_pleasant_weather</th>\n",
       "      <th>BELGRADE_pleasant_weather</th>\n",
       "      <th>BUDAPEST_pleasant_weather</th>\n",
       "      <th>DEBILT_pleasant_weather</th>\n",
       "      <th>DUSSELDORF_pleasant_weather</th>\n",
       "      <th>HEATHROW_pleasant_weather</th>\n",
       "      <th>KASSEL_pleasant_weather</th>\n",
       "      <th>LJUBLJANA_pleasant_weather</th>\n",
       "      <th>MAASTRICHT_pleasant_weather</th>\n",
       "      <th>MADRID_pleasant_weather</th>\n",
       "      <th>MUNCHENB_pleasant_weather</th>\n",
       "      <th>OSLO_pleasant_weather</th>\n",
       "      <th>SONNBLICK_pleasant_weather</th>\n",
       "      <th>STOCKHOLM_pleasant_weather</th>\n",
       "      <th>VALENTIA_pleasant_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22948</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22949</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22950 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
       "0                           0                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "...                       ...                        ...   \n",
       "22945                       0                          0   \n",
       "22946                       0                          0   \n",
       "22947                       0                          0   \n",
       "22948                       0                          0   \n",
       "22949                       0                          0   \n",
       "\n",
       "       BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
       "0                              0                        0   \n",
       "1                              0                        0   \n",
       "2                              0                        0   \n",
       "3                              0                        0   \n",
       "4                              0                        0   \n",
       "...                          ...                      ...   \n",
       "22945                          0                        0   \n",
       "22946                          0                        0   \n",
       "22947                          0                        0   \n",
       "22948                          0                        0   \n",
       "22949                          0                        0   \n",
       "\n",
       "       DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
       "0                                0                          0   \n",
       "1                                0                          0   \n",
       "2                                0                          0   \n",
       "3                                0                          0   \n",
       "4                                0                          0   \n",
       "...                            ...                        ...   \n",
       "22945                            0                          0   \n",
       "22946                            0                          0   \n",
       "22947                            0                          0   \n",
       "22948                            0                          0   \n",
       "22949                            0                          0   \n",
       "\n",
       "       KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "...                        ...                         ...   \n",
       "22945                        0                           0   \n",
       "22946                        0                           0   \n",
       "22947                        0                           0   \n",
       "22948                        0                           0   \n",
       "22949                        0                           0   \n",
       "\n",
       "       MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
       "0                                0                        0   \n",
       "1                                0                        0   \n",
       "2                                0                        0   \n",
       "3                                0                        0   \n",
       "4                                0                        0   \n",
       "...                            ...                      ...   \n",
       "22945                            0                        0   \n",
       "22946                            0                        0   \n",
       "22947                            0                        0   \n",
       "22948                            0                        0   \n",
       "22949                            0                        0   \n",
       "\n",
       "       MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
       "0                              0                      0   \n",
       "1                              0                      0   \n",
       "2                              0                      0   \n",
       "3                              0                      0   \n",
       "4                              0                      0   \n",
       "...                          ...                    ...   \n",
       "22945                          0                      0   \n",
       "22946                          0                      0   \n",
       "22947                          0                      0   \n",
       "22948                          0                      0   \n",
       "22949                          0                      0   \n",
       "\n",
       "       SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "22945                           0                           0   \n",
       "22946                           0                           0   \n",
       "22947                           0                           0   \n",
       "22948                           0                           0   \n",
       "22949                           0                           0   \n",
       "\n",
       "       VALENTIA_pleasant_weather  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "22945                          0  \n",
       "22946                          0  \n",
       "22947                          0  \n",
       "22948                          0  \n",
       "22949                          0  \n",
       "\n",
       "[22950 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the \"DATE\" from pleasent days dataset\n",
    "pleasant = pleasant.drop(columns = ['DATE'])\n",
    "pleasant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e3aa423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df to array.\n",
    "X = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b561d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape df\n",
    "X = df.values.reshape(-1, 15, 9)\n",
    "\n",
    "# Ensure the labels are in the same shape as X\n",
    "y = pleasant.values.reshape(-1, 15)\n",
    "\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ebf3bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e367cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c7d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22950,)\n"
     ]
    }
   ],
   "source": [
    "#Use argmax to get rid of one-hot encoding and supply the numerical value.\n",
    "y = np.argmax(y, axis = 1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baa21409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c935c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16065, 15, 9) (16065,)\n",
      "(6885, 15, 9) (6885,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b97fea",
   "metadata": {},
   "source": [
    "## 03. Bayesian optimization function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b3fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15 #_count_classes(y_train)\n",
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee63dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    optimizerD= {'Adam':Adam(learning_rate=learning_rate), 'SGD':SGD(learning_rate=learning_rate),\n",
    "                 'RMSprop':RMSprop(learning_rate=learning_rate), 'Adadelta':Adadelta(learning_rate=learning_rate),\n",
    "                 'Adagrad':Adagrad(learning_rate=learning_rate), 'Adamax':Adamax(learning_rate=learning_rate),\n",
    "                 'Nadam':Nadam(learning_rate=learning_rate), 'Ftrl':Ftrl(learning_rate=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifier(build_fn=cnn_model, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7265dac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n",
      "27/27 - 4s - 149ms/step - accuracy: 0.6263 - loss: 1.7516\n",
      "Epoch 2/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.2050\n",
      "Epoch 3/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1830\n",
      "Epoch 4/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1769\n",
      "Epoch 5/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1730\n",
      "Epoch 6/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1715\n",
      "Epoch 7/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1703\n",
      "Epoch 8/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1690\n",
      "Epoch 9/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1690\n",
      "Epoch 10/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1687\n",
      "Epoch 11/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1686\n",
      "Epoch 12/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1680\n",
      "Epoch 13/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1681\n",
      "Epoch 14/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1678\n",
      "Epoch 15/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1673\n",
      "Epoch 16/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1668\n",
      "Epoch 17/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1672\n",
      "Epoch 18/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1672\n",
      "Epoch 19/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1669\n",
      "Epoch 20/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1668\n",
      "Epoch 21/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1663\n",
      "Epoch 22/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1659\n",
      "Epoch 23/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1644\n",
      "Epoch 24/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1624\n",
      "Epoch 25/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1557\n",
      "Epoch 26/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1414\n",
      "Epoch 27/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.1164\n",
      "Epoch 28/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.0925\n",
      "Epoch 29/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6423 - loss: 1.0727\n",
      "Epoch 30/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6418 - loss: 1.0579\n",
      "Epoch 31/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6387 - loss: 1.0470\n",
      "Epoch 32/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6343 - loss: 1.0375\n",
      "Epoch 33/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6336 - loss: 1.0321\n",
      "Epoch 34/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6323 - loss: 1.0241\n",
      "Epoch 35/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6345 - loss: 1.0189\n",
      "Epoch 36/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6333 - loss: 1.0131\n",
      "Epoch 37/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6343 - loss: 1.0088\n",
      "Epoch 38/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6347 - loss: 1.0039\n",
      "Epoch 39/48\n",
      "27/27 - 0s - 12ms/step - accuracy: 0.6376 - loss: 1.0001\n",
      "Epoch 40/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6334 - loss: 0.9987\n",
      "Epoch 41/48\n",
      "27/27 - 0s - 11ms/step - accuracy: 0.6373 - loss: 0.9951\n",
      "Epoch 42/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6411 - loss: 0.9917\n",
      "Epoch 43/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6373 - loss: 0.9925\n",
      "Epoch 44/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6380 - loss: 0.9930\n",
      "Epoch 45/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6404 - loss: 0.9889\n",
      "Epoch 46/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6403 - loss: 0.9868\n",
      "Epoch 47/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6402 - loss: 0.9877\n",
      "Epoch 48/48\n",
      "27/27 - 0s - 10ms/step - accuracy: 0.6387 - loss: 0.9853\n",
      "7/7 - 1s - 83ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n",
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 38), dtype=float32, path=sequential_1/conv1d_1/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 38), dtype=float32, path=sequential_2/conv1d_2/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 38), dtype=float32, path=sequential_3/conv1d_3/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 38), dtype=float32, path=sequential_4/conv1d_4/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m1         | \u001b[30mnan       | \u001b[30m3.371     | \u001b[30m485.2     | \u001b[30m0.732     | \u001b[30m0.1796    | \u001b[30m48.08     | \u001b[30m1.312     | \u001b[30m1.058     | \u001b[30m1.866     | \u001b[30m0.06051   | \u001b[30m38.32     | \u001b[30m0.02058   | \u001b[30m6.789     |\n",
      "Epoch 1/75\n",
      "49/49 - 3s - 56ms/step - accuracy: 0.6422 - loss: nan\n",
      "Epoch 2/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 3/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 4/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 5/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 6/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 7/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 8/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 9/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 10/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 11/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 12/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 13/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 14/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 15/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 16/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 17/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 18/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 19/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 20/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 21/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 22/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 23/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 24/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 25/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 26/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 27/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 28/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 29/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 30/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 31/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 32/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 33/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 34/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 35/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 36/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 37/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 38/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 39/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 40/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 41/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 42/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 43/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 44/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 45/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 46/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 47/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 48/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 49/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 50/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 51/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 52/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 53/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 54/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 55/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 56/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 57/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 58/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 59/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 60/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 61/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 62/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 63/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 64/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 65/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 66/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 67/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 68/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 69/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 70/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 71/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 72/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 73/75\n",
      "49/49 - 0s - 5ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 74/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 75/75\n",
      "49/49 - 0s - 4ms/step - accuracy: 0.6423 - loss: nan\n",
      "13/13 - 0s - 21ms/step\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 16), dtype=float32, path=sequential_6/conv1d_6/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 16), dtype=float32, path=sequential_7/conv1d_7/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 16), dtype=float32, path=sequential_8/conv1d_8/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 16), dtype=float32, path=sequential_9/conv1d_9/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m2         | \u001b[30mnan       | \u001b[30m7.492     | \u001b[30m263.7     | \u001b[30m0.1818    | \u001b[30m0.05502   | \u001b[30m74.76     | \u001b[30m2.05      | \u001b[30m1.432     | \u001b[30m1.291     | \u001b[30m0.06157   | \u001b[30m15.58     | \u001b[30m0.2921    | \u001b[30m2.565     |\n",
      "Epoch 1/127\n",
      "30/30 - 6s - 195ms/step - accuracy: 0.6422 - loss: 1.0442\n",
      "Epoch 2/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.7463 - loss: 0.7508\n",
      "Epoch 3/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.7692 - loss: 0.6781\n",
      "Epoch 4/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.7846 - loss: 0.6197\n",
      "Epoch 5/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.8000 - loss: 0.5696\n",
      "Epoch 6/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.8136 - loss: 0.5225\n",
      "Epoch 7/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.8264 - loss: 0.4857\n",
      "Epoch 8/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.8410 - loss: 0.4465\n",
      "Epoch 9/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.8511 - loss: 0.4085\n",
      "Epoch 10/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.8570 - loss: 0.4040\n",
      "Epoch 11/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.8606 - loss: 0.3872\n",
      "Epoch 12/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.8761 - loss: 0.3531\n",
      "Epoch 13/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.8835 - loss: 0.3259\n",
      "Epoch 14/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.8856 - loss: 0.3267\n",
      "Epoch 15/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.8917 - loss: 0.3087\n",
      "Epoch 16/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.8960 - loss: 0.2997\n",
      "Epoch 17/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.8718 - loss: 0.3544\n",
      "Epoch 18/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9025 - loss: 0.2762\n",
      "Epoch 19/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9195 - loss: 0.2301\n",
      "Epoch 20/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9078 - loss: 0.2648\n",
      "Epoch 21/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.8861 - loss: 0.3287\n",
      "Epoch 22/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9038 - loss: 0.2650\n",
      "Epoch 23/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9202 - loss: 0.2283\n",
      "Epoch 24/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9240 - loss: 0.2150\n",
      "Epoch 25/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9321 - loss: 0.1945\n",
      "Epoch 26/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9229 - loss: 0.2200\n",
      "Epoch 27/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9158 - loss: 0.2424\n",
      "Epoch 28/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9343 - loss: 0.1888\n",
      "Epoch 29/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9365 - loss: 0.1771\n",
      "Epoch 30/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9320 - loss: 0.1989\n",
      "Epoch 31/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9416 - loss: 0.1651\n",
      "Epoch 32/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9454 - loss: 0.1605\n",
      "Epoch 33/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9455 - loss: 0.1580\n",
      "Epoch 34/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9399 - loss: 0.1674\n",
      "Epoch 35/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9370 - loss: 0.1846\n",
      "Epoch 36/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9403 - loss: 0.1709\n",
      "Epoch 37/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9342 - loss: 0.1871\n",
      "Epoch 38/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9547 - loss: 0.1293\n",
      "Epoch 39/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9409 - loss: 0.1767\n",
      "Epoch 40/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9336 - loss: 0.1879\n",
      "Epoch 41/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9613 - loss: 0.1193\n",
      "Epoch 42/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9581 - loss: 0.1190\n",
      "Epoch 43/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9630 - loss: 0.1112\n",
      "Epoch 44/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9380 - loss: 0.1714\n",
      "Epoch 45/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9668 - loss: 0.1010\n",
      "Epoch 46/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9688 - loss: 0.0916\n",
      "Epoch 47/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9082 - loss: 0.2690\n",
      "Epoch 48/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9499 - loss: 0.1424\n",
      "Epoch 49/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9602 - loss: 0.1116\n",
      "Epoch 50/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9651 - loss: 0.1009\n",
      "Epoch 51/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9733 - loss: 0.0836\n",
      "Epoch 52/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9517 - loss: 0.1485\n",
      "Epoch 53/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9376 - loss: 0.1730\n",
      "Epoch 54/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9458 - loss: 0.1600\n",
      "Epoch 55/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9653 - loss: 0.1065\n",
      "Epoch 56/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9787 - loss: 0.0654\n",
      "Epoch 57/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9778 - loss: 0.0696\n",
      "Epoch 58/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9532 - loss: 0.1392\n",
      "Epoch 59/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9532 - loss: 0.1338\n",
      "Epoch 60/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9763 - loss: 0.0697\n",
      "Epoch 61/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9691 - loss: 0.0964\n",
      "Epoch 62/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9596 - loss: 0.1257\n",
      "Epoch 63/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9651 - loss: 0.0997\n",
      "Epoch 64/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9808 - loss: 0.0594\n",
      "Epoch 65/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9765 - loss: 0.0713\n",
      "Epoch 66/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9826 - loss: 0.0567\n",
      "Epoch 67/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9864 - loss: 0.0448\n",
      "Epoch 68/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9862 - loss: 0.0454\n",
      "Epoch 69/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9862 - loss: 0.0462\n",
      "Epoch 70/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9069 - loss: 0.2919\n",
      "Epoch 71/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9668 - loss: 0.0925\n",
      "Epoch 72/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9807 - loss: 0.0585\n",
      "Epoch 73/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9656 - loss: 0.1004\n",
      "Epoch 74/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9239 - loss: 0.2282\n",
      "Epoch 75/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9553 - loss: 0.1177\n",
      "Epoch 76/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9729 - loss: 0.0774\n",
      "Epoch 77/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9768 - loss: 0.0699\n",
      "Epoch 78/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9874 - loss: 0.0423\n",
      "Epoch 79/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9903 - loss: 0.0334\n",
      "Epoch 80/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9940 - loss: 0.0257\n",
      "Epoch 81/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9920 - loss: 0.0281\n",
      "Epoch 82/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9876 - loss: 0.0427\n",
      "Epoch 83/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9812 - loss: 0.0668\n",
      "Epoch 84/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9702 - loss: 0.0879\n",
      "Epoch 85/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9888 - loss: 0.0358\n",
      "Epoch 86/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9810 - loss: 0.0618\n",
      "Epoch 87/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9818 - loss: 0.0554\n",
      "Epoch 88/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9902 - loss: 0.0353\n",
      "Epoch 89/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9933 - loss: 0.0245\n",
      "Epoch 90/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9665 - loss: 0.0949\n",
      "Epoch 91/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9803 - loss: 0.0539\n",
      "Epoch 92/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9848 - loss: 0.0453\n",
      "Epoch 93/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9752 - loss: 0.0767\n",
      "Epoch 94/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9796 - loss: 0.0599\n",
      "Epoch 95/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9902 - loss: 0.0302\n",
      "Epoch 96/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9962 - loss: 0.0162\n",
      "Epoch 97/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9974 - loss: 0.0148\n",
      "Epoch 98/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9974 - loss: 0.0131\n",
      "Epoch 99/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9955 - loss: 0.0191\n",
      "Epoch 100/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9951 - loss: 0.0225\n",
      "Epoch 101/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9978 - loss: 0.0127\n",
      "Epoch 102/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9991 - loss: 0.0083\n",
      "Epoch 103/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9854 - loss: 0.0474\n",
      "Epoch 104/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9898 - loss: 0.0331\n",
      "Epoch 105/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9658 - loss: 0.1044\n",
      "Epoch 106/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9786 - loss: 0.0587\n",
      "Epoch 107/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9842 - loss: 0.0464\n",
      "Epoch 108/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9878 - loss: 0.0363\n",
      "Epoch 109/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9936 - loss: 0.0220\n",
      "Epoch 110/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9921 - loss: 0.0267\n",
      "Epoch 111/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9955 - loss: 0.0172\n",
      "Epoch 112/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9948 - loss: 0.0193\n",
      "Epoch 113/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9873 - loss: 0.0349\n",
      "Epoch 114/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9720 - loss: 0.0770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9764 - loss: 0.0663\n",
      "Epoch 116/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9791 - loss: 0.0606\n",
      "Epoch 117/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9891 - loss: 0.0318\n",
      "Epoch 118/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9926 - loss: 0.0232\n",
      "Epoch 119/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9777 - loss: 0.0675\n",
      "Epoch 120/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9775 - loss: 0.0645\n",
      "Epoch 121/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9765 - loss: 0.0690\n",
      "Epoch 122/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9817 - loss: 0.0510\n",
      "Epoch 123/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9853 - loss: 0.0445\n",
      "Epoch 124/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9878 - loss: 0.0366\n",
      "Epoch 125/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9968 - loss: 0.0150\n",
      "Epoch 126/127\n",
      "30/30 - 0s - 11ms/step - accuracy: 0.9979 - loss: 0.0091\n",
      "Epoch 127/127\n",
      "30/30 - 0s - 10ms/step - accuracy: 0.9997 - loss: 0.0050\n",
      "8/8 - 0s - 48ms/step\n",
      "Epoch 1/127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 48), dtype=float32, path=sequential_11/conv1d_11/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 48), dtype=float32, path=sequential_12/conv1d_12/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 48), dtype=float32, path=sequential_13/conv1d_13/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 48), dtype=float32, path=sequential_14/conv1d_14/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m3         | \u001b[30mnan       | \u001b[30m4.105     | \u001b[30m435.6     | \u001b[30m0.1997    | \u001b[30m0.1543    | \u001b[30m126.6     | \u001b[30m1.093     | \u001b[30m1.608     | \u001b[30m1.171     | \u001b[30m0.00744   | \u001b[30m47.96     | \u001b[30m0.9656    | \u001b[30m5.659     |\n",
      "Epoch 1/42\n",
      "57/57 - 3s - 51ms/step - accuracy: 0.6239 - loss: 1.2807\n",
      "Epoch 2/42\n",
      "57/57 - 0s - 8ms/step - accuracy: 0.6459 - loss: 1.0506\n",
      "Epoch 3/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.6566 - loss: 1.0077\n",
      "Epoch 4/42\n",
      "57/57 - 0s - 8ms/step - accuracy: 0.6643 - loss: 0.9720\n",
      "Epoch 5/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.6793 - loss: 0.9331\n",
      "Epoch 6/42\n",
      "57/57 - 0s - 8ms/step - accuracy: 0.6858 - loss: 0.9012\n",
      "Epoch 7/42\n",
      "57/57 - 0s - 8ms/step - accuracy: 0.7023 - loss: 0.8691\n",
      "Epoch 8/42\n",
      "57/57 - 0s - 8ms/step - accuracy: 0.7113 - loss: 0.8457\n",
      "Epoch 9/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7206 - loss: 0.8212\n",
      "Epoch 10/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7281 - loss: 0.8052\n",
      "Epoch 11/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7336 - loss: 0.7881\n",
      "Epoch 12/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7397 - loss: 0.7772\n",
      "Epoch 13/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7407 - loss: 0.7653\n",
      "Epoch 14/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7434 - loss: 0.7586\n",
      "Epoch 15/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7485 - loss: 0.7469\n",
      "Epoch 16/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7515 - loss: 0.7380\n",
      "Epoch 17/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7558 - loss: 0.7306\n",
      "Epoch 18/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7579 - loss: 0.7200\n",
      "Epoch 19/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7634 - loss: 0.7174\n",
      "Epoch 20/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7614 - loss: 0.7104\n",
      "Epoch 21/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7659 - loss: 0.7032\n",
      "Epoch 22/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7659 - loss: 0.6968\n",
      "Epoch 23/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7674 - loss: 0.6941\n",
      "Epoch 24/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7683 - loss: 0.6862\n",
      "Epoch 25/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7691 - loss: 0.6865\n",
      "Epoch 26/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7723 - loss: 0.6780\n",
      "Epoch 27/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7703 - loss: 0.6784\n",
      "Epoch 28/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7746 - loss: 0.6713\n",
      "Epoch 29/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7720 - loss: 0.6665\n",
      "Epoch 30/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7754 - loss: 0.6631\n",
      "Epoch 31/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7773 - loss: 0.6600\n",
      "Epoch 32/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7789 - loss: 0.6603\n",
      "Epoch 33/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7787 - loss: 0.6549\n",
      "Epoch 34/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7771 - loss: 0.6516\n",
      "Epoch 35/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7803 - loss: 0.6467\n",
      "Epoch 36/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7793 - loss: 0.6461\n",
      "Epoch 37/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7815 - loss: 0.6443\n",
      "Epoch 38/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7814 - loss: 0.6382\n",
      "Epoch 39/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7804 - loss: 0.6391\n",
      "Epoch 40/42\n",
      "57/57 - 0s - 7ms/step - accuracy: 0.7832 - loss: 0.6369\n",
      "Epoch 41/42\n",
      "57/57 - 0s - 8ms/step - accuracy: 0.7834 - loss: 0.6330\n",
      "Epoch 42/42\n",
      "57/57 - 0s - 8ms/step - accuracy: 0.7852 - loss: 0.6290\n",
      "WARNING:tensorflow:5 out of the last 22 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017C5DC6B380> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "15/15 - 0s - 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 37), dtype=float32, path=sequential_16/conv1d_16/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 37), dtype=float32, path=sequential_17/conv1d_17/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 37), dtype=float32, path=sequential_18/conv1d_18/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 37), dtype=float32, path=sequential_19/conv1d_19/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m4         | \u001b[30mnan       | \u001b[30m2.742     | \u001b[30m229.3     | \u001b[30m0.6842    | \u001b[30m0.132     | \u001b[30m41.97     | \u001b[30m1.99      | \u001b[30m1.034     | \u001b[30m1.909     | \u001b[30m0.02662   | \u001b[30m36.5      | \u001b[30m0.3117    | \u001b[30m3.64      |\n",
      "Epoch 1/189\n",
      "51/51 - 3s - 58ms/step - accuracy: 0.6104 - loss: 1.3919\n",
      "Epoch 2/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.6648 - loss: 0.9610\n",
      "Epoch 3/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.6922 - loss: 0.8790\n",
      "Epoch 4/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7088 - loss: 0.8206\n",
      "Epoch 5/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7158 - loss: 0.7968\n",
      "Epoch 6/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7309 - loss: 0.7703\n",
      "Epoch 7/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7340 - loss: 0.7519\n",
      "Epoch 8/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7355 - loss: 0.7408\n",
      "Epoch 9/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7429 - loss: 0.7305\n",
      "Epoch 10/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7405 - loss: 0.7237\n",
      "Epoch 11/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7525 - loss: 0.7016\n",
      "Epoch 12/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7519 - loss: 0.7019\n",
      "Epoch 13/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7523 - loss: 0.6900\n",
      "Epoch 14/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7516 - loss: 0.6922\n",
      "Epoch 15/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7597 - loss: 0.6777\n",
      "Epoch 16/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7584 - loss: 0.6758\n",
      "Epoch 17/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7614 - loss: 0.6714\n",
      "Epoch 18/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7657 - loss: 0.6638\n",
      "Epoch 19/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7640 - loss: 0.6606\n",
      "Epoch 20/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7642 - loss: 0.6571\n",
      "Epoch 21/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7640 - loss: 0.6532\n",
      "Epoch 22/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7633 - loss: 0.6544\n",
      "Epoch 23/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7747 - loss: 0.6463\n",
      "Epoch 24/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7692 - loss: 0.6445\n",
      "Epoch 25/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7712 - loss: 0.6385\n",
      "Epoch 26/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7738 - loss: 0.6307\n",
      "Epoch 27/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7700 - loss: 0.6423\n",
      "Epoch 28/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7712 - loss: 0.6368\n",
      "Epoch 29/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7740 - loss: 0.6259\n",
      "Epoch 30/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7754 - loss: 0.6246\n",
      "Epoch 31/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7764 - loss: 0.6152\n",
      "Epoch 32/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7811 - loss: 0.6118\n",
      "Epoch 33/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7823 - loss: 0.6149\n",
      "Epoch 34/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7814 - loss: 0.6091\n",
      "Epoch 35/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7845 - loss: 0.6094\n",
      "Epoch 36/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7824 - loss: 0.6047\n",
      "Epoch 37/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7835 - loss: 0.5969\n",
      "Epoch 38/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7859 - loss: 0.5971\n",
      "Epoch 39/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7914 - loss: 0.5887\n",
      "Epoch 40/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7890 - loss: 0.5893\n",
      "Epoch 41/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7912 - loss: 0.5851\n",
      "Epoch 42/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7923 - loss: 0.5791\n",
      "Epoch 43/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.7935 - loss: 0.5708\n",
      "Epoch 44/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7961 - loss: 0.5633\n",
      "Epoch 45/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.7971 - loss: 0.5664\n",
      "Epoch 46/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8017 - loss: 0.5595\n",
      "Epoch 47/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8015 - loss: 0.5567\n",
      "Epoch 48/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8013 - loss: 0.5621\n",
      "Epoch 49/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8046 - loss: 0.5431\n",
      "Epoch 50/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8073 - loss: 0.5479\n",
      "Epoch 51/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8021 - loss: 0.5474\n",
      "Epoch 52/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8114 - loss: 0.5378\n",
      "Epoch 53/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8076 - loss: 0.5380\n",
      "Epoch 54/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8105 - loss: 0.5341\n",
      "Epoch 55/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8171 - loss: 0.5193\n",
      "Epoch 56/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8089 - loss: 0.5353\n",
      "Epoch 57/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8157 - loss: 0.5178\n",
      "Epoch 58/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8170 - loss: 0.5100\n",
      "Epoch 59/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8196 - loss: 0.5109\n",
      "Epoch 60/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8182 - loss: 0.5110\n",
      "Epoch 61/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8212 - loss: 0.5016\n",
      "Epoch 62/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8226 - loss: 0.5015\n",
      "Epoch 63/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8235 - loss: 0.4997\n",
      "Epoch 64/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8247 - loss: 0.5052\n",
      "Epoch 65/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8273 - loss: 0.4931\n",
      "Epoch 66/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8229 - loss: 0.5021\n",
      "Epoch 67/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8287 - loss: 0.4833\n",
      "Epoch 68/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8251 - loss: 0.4943\n",
      "Epoch 69/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8294 - loss: 0.4807\n",
      "Epoch 70/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8298 - loss: 0.4747\n",
      "Epoch 71/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8300 - loss: 0.4762\n",
      "Epoch 72/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8298 - loss: 0.4788\n",
      "Epoch 73/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8332 - loss: 0.4763\n",
      "Epoch 74/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8350 - loss: 0.4665\n",
      "Epoch 75/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8312 - loss: 0.4777\n",
      "Epoch 76/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8381 - loss: 0.4616\n",
      "Epoch 77/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8393 - loss: 0.4561\n",
      "Epoch 78/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8418 - loss: 0.4553\n",
      "Epoch 79/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8426 - loss: 0.4534\n",
      "Epoch 80/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8413 - loss: 0.4541\n",
      "Epoch 81/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8413 - loss: 0.4521\n",
      "Epoch 82/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8437 - loss: 0.4476\n",
      "Epoch 83/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8403 - loss: 0.4535\n",
      "Epoch 84/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8470 - loss: 0.4394\n",
      "Epoch 85/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8462 - loss: 0.4319\n",
      "Epoch 86/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8461 - loss: 0.4403\n",
      "Epoch 87/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8458 - loss: 0.4436\n",
      "Epoch 88/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8500 - loss: 0.4341\n",
      "Epoch 89/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8476 - loss: 0.4311\n",
      "Epoch 90/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8496 - loss: 0.4268\n",
      "Epoch 91/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8458 - loss: 0.4375\n",
      "Epoch 92/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8510 - loss: 0.4217\n",
      "Epoch 93/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8508 - loss: 0.4265\n",
      "Epoch 94/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8484 - loss: 0.4293\n",
      "Epoch 95/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8519 - loss: 0.4208\n",
      "Epoch 96/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8512 - loss: 0.4182\n",
      "Epoch 97/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8563 - loss: 0.4167\n",
      "Epoch 98/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8519 - loss: 0.4177\n",
      "Epoch 99/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8596 - loss: 0.4067\n",
      "Epoch 100/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8574 - loss: 0.4195\n",
      "Epoch 101/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8564 - loss: 0.4169\n",
      "Epoch 102/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8543 - loss: 0.4193\n",
      "Epoch 103/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8559 - loss: 0.4073\n",
      "Epoch 104/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8581 - loss: 0.4124\n",
      "Epoch 105/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8608 - loss: 0.4040\n",
      "Epoch 106/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8569 - loss: 0.4160\n",
      "Epoch 107/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8609 - loss: 0.4089\n",
      "Epoch 108/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8605 - loss: 0.3975\n",
      "Epoch 109/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8606 - loss: 0.3970\n",
      "Epoch 110/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8629 - loss: 0.3946\n",
      "Epoch 111/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8617 - loss: 0.3947\n",
      "Epoch 112/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8591 - loss: 0.4019\n",
      "Epoch 113/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8678 - loss: 0.3779\n",
      "Epoch 114/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8601 - loss: 0.3975\n",
      "Epoch 115/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8697 - loss: 0.3866\n",
      "Epoch 116/189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 - 0s - 7ms/step - accuracy: 0.8647 - loss: 0.3869\n",
      "Epoch 117/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8683 - loss: 0.3842\n",
      "Epoch 118/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8612 - loss: 0.4070\n",
      "Epoch 119/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8656 - loss: 0.3883\n",
      "Epoch 120/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8701 - loss: 0.3813\n",
      "Epoch 121/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8697 - loss: 0.3829\n",
      "Epoch 122/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8715 - loss: 0.3797\n",
      "Epoch 123/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8687 - loss: 0.3868\n",
      "Epoch 124/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8688 - loss: 0.3815\n",
      "Epoch 125/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8717 - loss: 0.3797\n",
      "Epoch 126/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8747 - loss: 0.3679\n",
      "Epoch 127/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8734 - loss: 0.3790\n",
      "Epoch 128/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8684 - loss: 0.3803\n",
      "Epoch 129/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8724 - loss: 0.3775\n",
      "Epoch 130/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8683 - loss: 0.3745\n",
      "Epoch 131/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8732 - loss: 0.3724\n",
      "Epoch 132/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8690 - loss: 0.3801\n",
      "Epoch 133/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8740 - loss: 0.3713\n",
      "Epoch 134/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8778 - loss: 0.3585\n",
      "Epoch 135/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8725 - loss: 0.3748\n",
      "Epoch 136/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8765 - loss: 0.3638\n",
      "Epoch 137/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8732 - loss: 0.3750\n",
      "Epoch 138/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8701 - loss: 0.3677\n",
      "Epoch 139/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8757 - loss: 0.3633\n",
      "Epoch 140/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8724 - loss: 0.3753\n",
      "Epoch 141/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8715 - loss: 0.3723\n",
      "Epoch 142/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8784 - loss: 0.3517\n",
      "Epoch 143/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8773 - loss: 0.3572\n",
      "Epoch 144/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8771 - loss: 0.3666\n",
      "Epoch 145/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8700 - loss: 0.3778\n",
      "Epoch 146/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8785 - loss: 0.3470\n",
      "Epoch 147/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8757 - loss: 0.3643\n",
      "Epoch 148/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8762 - loss: 0.3606\n",
      "Epoch 149/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8811 - loss: 0.3515\n",
      "Epoch 150/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8809 - loss: 0.3528\n",
      "Epoch 151/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8777 - loss: 0.3514\n",
      "Epoch 152/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8755 - loss: 0.3571\n",
      "Epoch 153/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8779 - loss: 0.3534\n",
      "Epoch 154/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8857 - loss: 0.3372\n",
      "Epoch 155/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8765 - loss: 0.3626\n",
      "Epoch 156/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8855 - loss: 0.3388\n",
      "Epoch 157/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8798 - loss: 0.3563\n",
      "Epoch 158/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8797 - loss: 0.3511\n",
      "Epoch 159/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8796 - loss: 0.3503\n",
      "Epoch 160/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8841 - loss: 0.3413\n",
      "Epoch 161/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8848 - loss: 0.3444\n",
      "Epoch 162/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8810 - loss: 0.3516\n",
      "Epoch 163/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8820 - loss: 0.3421\n",
      "Epoch 164/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8833 - loss: 0.3460\n",
      "Epoch 165/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8800 - loss: 0.3544\n",
      "Epoch 166/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8761 - loss: 0.3625\n",
      "Epoch 167/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8845 - loss: 0.3418\n",
      "Epoch 168/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8859 - loss: 0.3344\n",
      "Epoch 169/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8791 - loss: 0.3571\n",
      "Epoch 170/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8844 - loss: 0.3348\n",
      "Epoch 171/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8835 - loss: 0.3418\n",
      "Epoch 172/189\n",
      "51/51 - 0s - 8ms/step - accuracy: 0.8834 - loss: 0.3452\n",
      "Epoch 173/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8851 - loss: 0.3378\n",
      "Epoch 174/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8833 - loss: 0.3447\n",
      "Epoch 175/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8867 - loss: 0.3377\n",
      "Epoch 176/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8834 - loss: 0.3380\n",
      "Epoch 177/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8841 - loss: 0.3423\n",
      "Epoch 178/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8909 - loss: 0.3213\n",
      "Epoch 179/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8842 - loss: 0.3347\n",
      "Epoch 180/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8921 - loss: 0.3180\n",
      "Epoch 181/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8858 - loss: 0.3428\n",
      "Epoch 182/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8859 - loss: 0.3231\n",
      "Epoch 183/189\n",
      "51/51 - 0s - 6ms/step - accuracy: 0.8890 - loss: 0.3334\n",
      "Epoch 184/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8915 - loss: 0.3212\n",
      "Epoch 185/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8918 - loss: 0.3195\n",
      "Epoch 186/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8904 - loss: 0.3264\n",
      "Epoch 187/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8894 - loss: 0.3250\n",
      "Epoch 188/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8912 - loss: 0.3262\n",
      "Epoch 189/189\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.8874 - loss: 0.3308\n",
      "13/13 - 0s - 28ms/step\n",
      "Epoch 1/189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(3, 9, 18), dtype=float32, path=sequential_21/conv1d_21/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(3, 9, 18), dtype=float32, path=sequential_22/conv1d_22/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(3, 9, 18), dtype=float32, path=sequential_23/conv1d_23/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(3, 9, 18), dtype=float32, path=sequential_24/conv1d_24/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m5         | \u001b[30mnan       | \u001b[30m4.92      | \u001b[30m255.5     | \u001b[30m0.9696    | \u001b[30m0.2325    | \u001b[30m189.1     | \u001b[30m2.79      | \u001b[30m1.598     | \u001b[30m1.922     | \u001b[30m0.009761  | \u001b[30m17.84     | \u001b[30m0.04523   | \u001b[30m2.277     |\n",
      "Epoch 1/71\n",
      "46/46 - 5s - 106ms/step - accuracy: 0.6724 - loss: 0.9650\n",
      "Epoch 2/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.7547 - loss: 0.7148\n",
      "Epoch 3/71\n",
      "46/46 - 0s - 11ms/step - accuracy: 0.7701 - loss: 0.6579\n",
      "Epoch 4/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.7804 - loss: 0.6203\n",
      "Epoch 5/71\n",
      "46/46 - 0s - 11ms/step - accuracy: 0.7820 - loss: 0.6135\n",
      "Epoch 6/71\n",
      "46/46 - 0s - 11ms/step - accuracy: 0.7879 - loss: 0.5879\n",
      "Epoch 7/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8010 - loss: 0.5579\n",
      "Epoch 8/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.7991 - loss: 0.5596\n",
      "Epoch 9/71\n",
      "46/46 - 0s - 11ms/step - accuracy: 0.8037 - loss: 0.5445\n",
      "Epoch 10/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8156 - loss: 0.5233\n",
      "Epoch 11/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8170 - loss: 0.5058\n",
      "Epoch 12/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8228 - loss: 0.4831\n",
      "Epoch 13/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8286 - loss: 0.4716\n",
      "Epoch 14/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8369 - loss: 0.4482\n",
      "Epoch 15/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8409 - loss: 0.4337\n",
      "Epoch 16/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8426 - loss: 0.4372\n",
      "Epoch 17/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8554 - loss: 0.4053\n",
      "Epoch 18/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8517 - loss: 0.4075\n",
      "Epoch 19/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8519 - loss: 0.4022\n",
      "Epoch 20/71\n",
      "46/46 - 0s - 11ms/step - accuracy: 0.8569 - loss: 0.3976\n",
      "Epoch 21/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8627 - loss: 0.3859\n",
      "Epoch 22/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8734 - loss: 0.3459\n",
      "Epoch 23/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8712 - loss: 0.3551\n",
      "Epoch 24/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8794 - loss: 0.3312\n",
      "Epoch 25/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8890 - loss: 0.3012\n",
      "Epoch 26/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8921 - loss: 0.2979\n",
      "Epoch 27/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9025 - loss: 0.2660\n",
      "Epoch 28/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8596 - loss: 0.3908\n",
      "Epoch 29/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8931 - loss: 0.3142\n",
      "Epoch 30/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8668 - loss: 0.3638\n",
      "Epoch 31/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9050 - loss: 0.2634\n",
      "Epoch 32/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9072 - loss: 0.2598\n",
      "Epoch 33/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8695 - loss: 0.3662\n",
      "Epoch 34/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8750 - loss: 0.3358\n",
      "Epoch 35/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9058 - loss: 0.2621\n",
      "Epoch 36/71\n",
      "46/46 - 0s - 11ms/step - accuracy: 0.9140 - loss: 0.2381\n",
      "Epoch 37/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9155 - loss: 0.2329\n",
      "Epoch 38/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9060 - loss: 0.2585\n",
      "Epoch 39/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9262 - loss: 0.2090\n",
      "Epoch 40/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9229 - loss: 0.2164\n",
      "Epoch 41/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9164 - loss: 0.2340\n",
      "Epoch 42/71\n",
      "46/46 - 0s - 11ms/step - accuracy: 0.9143 - loss: 0.2449\n",
      "Epoch 43/71\n",
      "46/46 - 0s - 11ms/step - accuracy: 0.9172 - loss: 0.2333\n",
      "Epoch 44/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9204 - loss: 0.2246\n",
      "Epoch 45/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9013 - loss: 0.2901\n",
      "Epoch 46/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9278 - loss: 0.1998\n",
      "Epoch 47/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9306 - loss: 0.1962\n",
      "Epoch 48/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9154 - loss: 0.2393\n",
      "Epoch 49/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9293 - loss: 0.1924\n",
      "Epoch 50/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9283 - loss: 0.2026\n",
      "Epoch 51/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9292 - loss: 0.2004\n",
      "Epoch 52/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9230 - loss: 0.2181\n",
      "Epoch 53/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9031 - loss: 0.2751\n",
      "Epoch 54/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9319 - loss: 0.1893\n",
      "Epoch 55/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9420 - loss: 0.1548\n",
      "Epoch 56/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9388 - loss: 0.1744\n",
      "Epoch 57/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9226 - loss: 0.2235\n",
      "Epoch 58/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9238 - loss: 0.2193\n",
      "Epoch 59/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9269 - loss: 0.2053\n",
      "Epoch 60/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9330 - loss: 0.1983\n",
      "Epoch 61/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9290 - loss: 0.1964\n",
      "Epoch 62/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9346 - loss: 0.1858\n",
      "Epoch 63/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9500 - loss: 0.1387\n",
      "Epoch 64/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9252 - loss: 0.2100\n",
      "Epoch 65/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9402 - loss: 0.1760\n",
      "Epoch 66/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9353 - loss: 0.1836\n",
      "Epoch 67/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9362 - loss: 0.1835\n",
      "Epoch 68/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.8942 - loss: 0.3068\n",
      "Epoch 69/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9453 - loss: 0.1581\n",
      "Epoch 70/71\n",
      "46/46 - 1s - 11ms/step - accuracy: 0.9447 - loss: 0.1626\n",
      "Epoch 71/71\n",
      "46/46 - 0s - 10ms/step - accuracy: 0.9544 - loss: 0.1258\n",
      "12/12 - 0s - 33ms/step\n",
      "Epoch 1/71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/71\n",
      "Epoch 1/71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 49), dtype=float32, path=sequential_26/conv1d_26/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 49), dtype=float32, path=sequential_27/conv1d_27/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 49), dtype=float32, path=sequential_28/conv1d_28/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 49), dtype=float32, path=sequential_29/conv1d_29/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m6         | \u001b[30mnan       | \u001b[30m3.498     | \u001b[30m281.4     | \u001b[30m0.8287    | \u001b[30m0.107     | \u001b[30m70.57     | \u001b[30m2.085     | \u001b[30m1.141     | \u001b[30m1.802     | \u001b[30m0.008381  | \u001b[30m49.48     | \u001b[30m0.7722    | \u001b[30m1.391     |\n",
      "Epoch 1/159\n",
      "29/29 - 2s - 54ms/step - accuracy: 0.5843 - loss: 2.4538\n",
      "Epoch 2/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6432 - loss: 1.0411\n",
      "Epoch 3/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6591 - loss: 0.9815\n",
      "Epoch 4/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6644 - loss: 0.9446\n",
      "Epoch 5/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6723 - loss: 0.9255\n",
      "Epoch 6/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6743 - loss: 0.9154\n",
      "Epoch 7/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6828 - loss: 0.9009\n",
      "Epoch 8/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6858 - loss: 0.8936\n",
      "Epoch 9/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6840 - loss: 0.8813\n",
      "Epoch 10/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6869 - loss: 0.8795\n",
      "Epoch 11/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6951 - loss: 0.8541\n",
      "Epoch 12/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6980 - loss: 0.8577\n",
      "Epoch 13/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6994 - loss: 0.8510\n",
      "Epoch 14/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.6965 - loss: 0.8525\n",
      "Epoch 15/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7028 - loss: 0.8468\n",
      "Epoch 16/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7088 - loss: 0.8298\n",
      "Epoch 17/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7113 - loss: 0.8248\n",
      "Epoch 18/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7103 - loss: 0.8278\n",
      "Epoch 19/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7233 - loss: 0.8015\n",
      "Epoch 20/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7163 - loss: 0.8114\n",
      "Epoch 21/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7194 - loss: 0.8069\n",
      "Epoch 22/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7134 - loss: 0.8003\n",
      "Epoch 23/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7232 - loss: 0.7938\n",
      "Epoch 24/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7151 - loss: 0.8018\n",
      "Epoch 25/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7215 - loss: 0.7907\n",
      "Epoch 26/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7206 - loss: 0.7864\n",
      "Epoch 27/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7299 - loss: 0.7841\n",
      "Epoch 28/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7242 - loss: 0.7769\n",
      "Epoch 29/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7263 - loss: 0.7828\n",
      "Epoch 30/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7227 - loss: 0.7788\n",
      "Epoch 31/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7247 - loss: 0.7736\n",
      "Epoch 32/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7273 - loss: 0.7708\n",
      "Epoch 33/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7309 - loss: 0.7710\n",
      "Epoch 34/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7309 - loss: 0.7696\n",
      "Epoch 35/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7291 - loss: 0.7676\n",
      "Epoch 36/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7347 - loss: 0.7578\n",
      "Epoch 37/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7291 - loss: 0.7635\n",
      "Epoch 38/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7295 - loss: 0.7635\n",
      "Epoch 39/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7314 - loss: 0.7562\n",
      "Epoch 40/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7361 - loss: 0.7466\n",
      "Epoch 41/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7288 - loss: 0.7591\n",
      "Epoch 42/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7338 - loss: 0.7536\n",
      "Epoch 43/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7281 - loss: 0.7665\n",
      "Epoch 44/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7379 - loss: 0.7441\n",
      "Epoch 45/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7394 - loss: 0.7451\n",
      "Epoch 46/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7362 - loss: 0.7503\n",
      "Epoch 47/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7365 - loss: 0.7428\n",
      "Epoch 48/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7332 - loss: 0.7507\n",
      "Epoch 49/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7365 - loss: 0.7432\n",
      "Epoch 50/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7368 - loss: 0.7481\n",
      "Epoch 51/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7403 - loss: 0.7398\n",
      "Epoch 52/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7374 - loss: 0.7460\n",
      "Epoch 53/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7346 - loss: 0.7443\n",
      "Epoch 54/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7338 - loss: 0.7459\n",
      "Epoch 55/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7422 - loss: 0.7360\n",
      "Epoch 56/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7426 - loss: 0.7344\n",
      "Epoch 57/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7422 - loss: 0.7322\n",
      "Epoch 58/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7389 - loss: 0.7347\n",
      "Epoch 59/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7416 - loss: 0.7392\n",
      "Epoch 60/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7423 - loss: 0.7312\n",
      "Epoch 61/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7456 - loss: 0.7229\n",
      "Epoch 62/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7435 - loss: 0.7265\n",
      "Epoch 63/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7429 - loss: 0.7321\n",
      "Epoch 64/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7391 - loss: 0.7300\n",
      "Epoch 65/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7489 - loss: 0.7167\n",
      "Epoch 66/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7505 - loss: 0.7141\n",
      "Epoch 67/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7359 - loss: 0.7366\n",
      "Epoch 68/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7450 - loss: 0.7257\n",
      "Epoch 69/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7453 - loss: 0.7189\n",
      "Epoch 70/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7443 - loss: 0.7265\n",
      "Epoch 71/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7540 - loss: 0.7142\n",
      "Epoch 72/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7501 - loss: 0.7118\n",
      "Epoch 73/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7450 - loss: 0.7156\n",
      "Epoch 74/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7460 - loss: 0.7199\n",
      "Epoch 75/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7439 - loss: 0.7211\n",
      "Epoch 76/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7572 - loss: 0.6983\n",
      "Epoch 77/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7507 - loss: 0.7068\n",
      "Epoch 78/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7510 - loss: 0.7119\n",
      "Epoch 79/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7545 - loss: 0.7042\n",
      "Epoch 80/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7461 - loss: 0.7138\n",
      "Epoch 81/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7439 - loss: 0.7137\n",
      "Epoch 82/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7530 - loss: 0.6996\n",
      "Epoch 83/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7473 - loss: 0.7119\n",
      "Epoch 84/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7512 - loss: 0.7056\n",
      "Epoch 85/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7543 - loss: 0.6986\n",
      "Epoch 86/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7502 - loss: 0.7029\n",
      "Epoch 87/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7505 - loss: 0.7142\n",
      "Epoch 88/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7539 - loss: 0.7012\n",
      "Epoch 89/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7524 - loss: 0.7005\n",
      "Epoch 90/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7521 - loss: 0.7023\n",
      "Epoch 91/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7578 - loss: 0.6896\n",
      "Epoch 92/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7586 - loss: 0.6923\n",
      "Epoch 93/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7572 - loss: 0.6970\n",
      "Epoch 94/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7561 - loss: 0.6919\n",
      "Epoch 95/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7506 - loss: 0.7009\n",
      "Epoch 96/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7572 - loss: 0.6855\n",
      "Epoch 97/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7494 - loss: 0.6990\n",
      "Epoch 98/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7584 - loss: 0.6876\n",
      "Epoch 99/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7480 - loss: 0.7025\n",
      "Epoch 100/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7545 - loss: 0.6983\n",
      "Epoch 101/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7575 - loss: 0.6885\n",
      "Epoch 102/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7529 - loss: 0.6942\n",
      "Epoch 103/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7514 - loss: 0.6966\n",
      "Epoch 104/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7547 - loss: 0.6988\n",
      "Epoch 105/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7586 - loss: 0.6752\n",
      "Epoch 106/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7580 - loss: 0.6897\n",
      "Epoch 107/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7516 - loss: 0.6909\n",
      "Epoch 108/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7545 - loss: 0.6902\n",
      "Epoch 109/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7637 - loss: 0.6771\n",
      "Epoch 110/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7518 - loss: 0.6906\n",
      "Epoch 111/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7590 - loss: 0.6852\n",
      "Epoch 112/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7578 - loss: 0.6881\n",
      "Epoch 113/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7608 - loss: 0.6765\n",
      "Epoch 114/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7546 - loss: 0.6891\n",
      "Epoch 115/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7610 - loss: 0.6829\n",
      "Epoch 116/159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - 8ms/step - accuracy: 0.7572 - loss: 0.6824\n",
      "Epoch 117/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7589 - loss: 0.6766\n",
      "Epoch 118/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7516 - loss: 0.6920\n",
      "Epoch 119/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7513 - loss: 0.6872\n",
      "Epoch 120/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7662 - loss: 0.6683\n",
      "Epoch 121/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7608 - loss: 0.6790\n",
      "Epoch 122/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7660 - loss: 0.6656\n",
      "Epoch 123/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7531 - loss: 0.6858\n",
      "Epoch 124/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7632 - loss: 0.6691\n",
      "Epoch 125/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7649 - loss: 0.6725\n",
      "Epoch 126/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7600 - loss: 0.6738\n",
      "Epoch 127/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7633 - loss: 0.6652\n",
      "Epoch 128/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7658 - loss: 0.6689\n",
      "Epoch 129/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7625 - loss: 0.6686\n",
      "Epoch 130/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7518 - loss: 0.6909\n",
      "Epoch 131/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7627 - loss: 0.6703\n",
      "Epoch 132/159\n",
      "29/29 - 0s - 9ms/step - accuracy: 0.7592 - loss: 0.6742\n",
      "Epoch 133/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7578 - loss: 0.6723\n",
      "Epoch 134/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7658 - loss: 0.6686\n",
      "Epoch 135/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7621 - loss: 0.6719\n",
      "Epoch 136/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7624 - loss: 0.6699\n",
      "Epoch 137/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7682 - loss: 0.6591\n",
      "Epoch 138/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7601 - loss: 0.6771\n",
      "Epoch 139/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7682 - loss: 0.6573\n",
      "Epoch 140/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7664 - loss: 0.6569\n",
      "Epoch 141/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7667 - loss: 0.6633\n",
      "Epoch 142/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7549 - loss: 0.6768\n",
      "Epoch 143/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7586 - loss: 0.6692\n",
      "Epoch 144/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7608 - loss: 0.6656\n",
      "Epoch 145/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7607 - loss: 0.6684\n",
      "Epoch 146/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7636 - loss: 0.6677\n",
      "Epoch 147/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7676 - loss: 0.6580\n",
      "Epoch 148/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7608 - loss: 0.6688\n",
      "Epoch 149/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7697 - loss: 0.6543\n",
      "Epoch 150/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7649 - loss: 0.6611\n",
      "Epoch 151/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7607 - loss: 0.6720\n",
      "Epoch 152/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7603 - loss: 0.6629\n",
      "Epoch 153/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7629 - loss: 0.6687\n",
      "Epoch 154/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7653 - loss: 0.6515\n",
      "Epoch 155/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7620 - loss: 0.6584\n",
      "Epoch 156/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7663 - loss: 0.6526\n",
      "Epoch 157/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7656 - loss: 0.6544\n",
      "Epoch 158/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7641 - loss: 0.6533\n",
      "Epoch 159/159\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.7648 - loss: 0.6564\n",
      "8/8 - 0s - 36ms/step\n",
      "Epoch 1/159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 35), dtype=float32, path=sequential_31/conv1d_31/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 35), dtype=float32, path=sequential_32/conv1d_32/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 35), dtype=float32, path=sequential_33/conv1d_33/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 35), dtype=float32, path=sequential_34/conv1d_34/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m7         | \u001b[30mnan       | \u001b[30m0.0497    | \u001b[30m444.6     | \u001b[30m0.7069    | \u001b[30m0.2187    | \u001b[30m158.8     | \u001b[30m1.148     | \u001b[30m1.358     | \u001b[30m1.116     | \u001b[30m0.08645   | \u001b[30m34.93     | \u001b[30m0.3309    | \u001b[30m0.4449    |\n",
      "Epoch 1/180\n",
      "44/44 - 4s - 101ms/step - accuracy: 0.1962 - loss: 2.5895\n",
      "Epoch 2/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6096 - loss: 2.1250\n",
      "Epoch 3/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6402 - loss: 1.6814\n",
      "Epoch 4/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6419 - loss: 1.3946\n",
      "Epoch 5/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6422 - loss: 1.2569\n",
      "Epoch 6/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6425 - loss: 1.1863\n",
      "Epoch 7/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6431 - loss: 1.1438\n",
      "Epoch 8/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6440 - loss: 1.1125\n",
      "Epoch 9/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6469 - loss: 1.0872\n",
      "Epoch 10/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6509 - loss: 1.0685\n",
      "Epoch 11/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6537 - loss: 1.0505\n",
      "Epoch 12/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6554 - loss: 1.0356\n",
      "Epoch 13/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6599 - loss: 1.0208\n",
      "Epoch 14/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6635 - loss: 1.0100\n",
      "Epoch 15/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6666 - loss: 0.9963\n",
      "Epoch 16/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6679 - loss: 0.9855\n",
      "Epoch 17/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6727 - loss: 0.9750\n",
      "Epoch 18/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6769 - loss: 0.9647\n",
      "Epoch 19/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6756 - loss: 0.9548\n",
      "Epoch 20/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6790 - loss: 0.9472\n",
      "Epoch 21/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6802 - loss: 0.9381\n",
      "Epoch 22/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6820 - loss: 0.9302\n",
      "Epoch 23/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6814 - loss: 0.9223\n",
      "Epoch 24/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6839 - loss: 0.9152\n",
      "Epoch 25/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6892 - loss: 0.9083\n",
      "Epoch 26/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6887 - loss: 0.9014\n",
      "Epoch 27/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6932 - loss: 0.8961\n",
      "Epoch 28/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6937 - loss: 0.8881\n",
      "Epoch 29/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6941 - loss: 0.8844\n",
      "Epoch 30/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6944 - loss: 0.8807\n",
      "Epoch 31/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6983 - loss: 0.8740\n",
      "Epoch 32/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.6987 - loss: 0.8706\n",
      "Epoch 33/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7021 - loss: 0.8642\n",
      "Epoch 34/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7041 - loss: 0.8589\n",
      "Epoch 35/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7034 - loss: 0.8561\n",
      "Epoch 36/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7042 - loss: 0.8499\n",
      "Epoch 37/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7081 - loss: 0.8467\n",
      "Epoch 38/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7080 - loss: 0.8439\n",
      "Epoch 39/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7100 - loss: 0.8403\n",
      "Epoch 40/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7102 - loss: 0.8359\n",
      "Epoch 41/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7136 - loss: 0.8314\n",
      "Epoch 42/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7155 - loss: 0.8278\n",
      "Epoch 43/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7161 - loss: 0.8241\n",
      "Epoch 44/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7192 - loss: 0.8197\n",
      "Epoch 45/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7211 - loss: 0.8140\n",
      "Epoch 46/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7210 - loss: 0.8108\n",
      "Epoch 47/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7228 - loss: 0.8098\n",
      "Epoch 48/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7268 - loss: 0.8058\n",
      "Epoch 49/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7258 - loss: 0.8016\n",
      "Epoch 50/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7281 - loss: 0.8002\n",
      "Epoch 51/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7270 - loss: 0.7955\n",
      "Epoch 52/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7316 - loss: 0.7925\n",
      "Epoch 53/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7318 - loss: 0.7899\n",
      "Epoch 54/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7336 - loss: 0.7858\n",
      "Epoch 55/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7378 - loss: 0.7815\n",
      "Epoch 56/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7341 - loss: 0.7793\n",
      "Epoch 57/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7369 - loss: 0.7765\n",
      "Epoch 58/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7351 - loss: 0.7753\n",
      "Epoch 59/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7369 - loss: 0.7711\n",
      "Epoch 60/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7368 - loss: 0.7692\n",
      "Epoch 61/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7386 - loss: 0.7663\n",
      "Epoch 62/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7416 - loss: 0.7646\n",
      "Epoch 63/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7384 - loss: 0.7647\n",
      "Epoch 64/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7442 - loss: 0.7593\n",
      "Epoch 65/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7426 - loss: 0.7575\n",
      "Epoch 66/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7427 - loss: 0.7570\n",
      "Epoch 67/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7466 - loss: 0.7513\n",
      "Epoch 68/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7453 - loss: 0.7508\n",
      "Epoch 69/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7463 - loss: 0.7495\n",
      "Epoch 70/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7466 - loss: 0.7463\n",
      "Epoch 71/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7497 - loss: 0.7458\n",
      "Epoch 72/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7474 - loss: 0.7420\n",
      "Epoch 73/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7471 - loss: 0.7427\n",
      "Epoch 74/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7494 - loss: 0.7398\n",
      "Epoch 75/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7491 - loss: 0.7411\n",
      "Epoch 76/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7474 - loss: 0.7363\n",
      "Epoch 77/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7502 - loss: 0.7316\n",
      "Epoch 78/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7502 - loss: 0.7336\n",
      "Epoch 79/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7490 - loss: 0.7328\n",
      "Epoch 80/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7476 - loss: 0.7300\n",
      "Epoch 81/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7515 - loss: 0.7276\n",
      "Epoch 82/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7499 - loss: 0.7278\n",
      "Epoch 83/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7517 - loss: 0.7271\n",
      "Epoch 84/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7533 - loss: 0.7250\n",
      "Epoch 85/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7530 - loss: 0.7255\n",
      "Epoch 86/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7533 - loss: 0.7226\n",
      "Epoch 87/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7547 - loss: 0.7204\n",
      "Epoch 88/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7544 - loss: 0.7168\n",
      "Epoch 89/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7563 - loss: 0.7195\n",
      "Epoch 90/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7564 - loss: 0.7165\n",
      "Epoch 91/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7568 - loss: 0.7156\n",
      "Epoch 92/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7537 - loss: 0.7151\n",
      "Epoch 93/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7565 - loss: 0.7131\n",
      "Epoch 94/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7556 - loss: 0.7151\n",
      "Epoch 95/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7567 - loss: 0.7102\n",
      "Epoch 96/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7549 - loss: 0.7098\n",
      "Epoch 97/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7570 - loss: 0.7083\n",
      "Epoch 98/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7571 - loss: 0.7075\n",
      "Epoch 99/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7619 - loss: 0.7045\n",
      "Epoch 100/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7582 - loss: 0.7040\n",
      "Epoch 101/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7600 - loss: 0.7022\n",
      "Epoch 102/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7583 - loss: 0.7056\n",
      "Epoch 103/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7602 - loss: 0.7005\n",
      "Epoch 104/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7587 - loss: 0.7027\n",
      "Epoch 105/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7602 - loss: 0.7015\n",
      "Epoch 106/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7601 - loss: 0.7002\n",
      "Epoch 107/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7592 - loss: 0.7001\n",
      "Epoch 108/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7606 - loss: 0.6957\n",
      "Epoch 109/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7606 - loss: 0.6969\n",
      "Epoch 110/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7591 - loss: 0.6975\n",
      "Epoch 111/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7607 - loss: 0.6945\n",
      "Epoch 112/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7616 - loss: 0.6943\n",
      "Epoch 113/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7614 - loss: 0.6925\n",
      "Epoch 114/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7598 - loss: 0.6954\n",
      "Epoch 115/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7638 - loss: 0.6882\n",
      "Epoch 116/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 - 0s - 8ms/step - accuracy: 0.7631 - loss: 0.6900\n",
      "Epoch 117/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7628 - loss: 0.6893\n",
      "Epoch 118/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7628 - loss: 0.6896\n",
      "Epoch 119/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7631 - loss: 0.6881\n",
      "Epoch 120/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7652 - loss: 0.6879\n",
      "Epoch 121/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7622 - loss: 0.6864\n",
      "Epoch 122/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7656 - loss: 0.6854\n",
      "Epoch 123/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7627 - loss: 0.6861\n",
      "Epoch 124/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7660 - loss: 0.6879\n",
      "Epoch 125/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7674 - loss: 0.6821\n",
      "Epoch 126/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7610 - loss: 0.6850\n",
      "Epoch 127/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7638 - loss: 0.6827\n",
      "Epoch 128/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7644 - loss: 0.6814\n",
      "Epoch 129/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7633 - loss: 0.6820\n",
      "Epoch 130/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7653 - loss: 0.6811\n",
      "Epoch 131/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7668 - loss: 0.6795\n",
      "Epoch 132/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7672 - loss: 0.6791\n",
      "Epoch 133/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7666 - loss: 0.6770\n",
      "Epoch 134/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7674 - loss: 0.6755\n",
      "Epoch 135/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7642 - loss: 0.6770\n",
      "Epoch 136/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7688 - loss: 0.6747\n",
      "Epoch 137/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7676 - loss: 0.6747\n",
      "Epoch 138/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7638 - loss: 0.6732\n",
      "Epoch 139/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7649 - loss: 0.6746\n",
      "Epoch 140/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7645 - loss: 0.6749\n",
      "Epoch 141/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7669 - loss: 0.6713\n",
      "Epoch 142/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7691 - loss: 0.6716\n",
      "Epoch 143/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7699 - loss: 0.6693\n",
      "Epoch 144/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7668 - loss: 0.6734\n",
      "Epoch 145/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7691 - loss: 0.6676\n",
      "Epoch 146/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7682 - loss: 0.6689\n",
      "Epoch 147/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7698 - loss: 0.6680\n",
      "Epoch 148/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7679 - loss: 0.6682\n",
      "Epoch 149/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7677 - loss: 0.6684\n",
      "Epoch 150/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7686 - loss: 0.6663\n",
      "Epoch 151/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7708 - loss: 0.6674\n",
      "Epoch 152/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7701 - loss: 0.6640\n",
      "Epoch 153/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7686 - loss: 0.6640\n",
      "Epoch 154/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7709 - loss: 0.6643\n",
      "Epoch 155/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7721 - loss: 0.6631\n",
      "Epoch 156/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7697 - loss: 0.6637\n",
      "Epoch 157/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7720 - loss: 0.6611\n",
      "Epoch 158/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7689 - loss: 0.6650\n",
      "Epoch 159/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7698 - loss: 0.6631\n",
      "Epoch 160/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7710 - loss: 0.6632\n",
      "Epoch 161/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7702 - loss: 0.6610\n",
      "Epoch 162/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7719 - loss: 0.6595\n",
      "Epoch 163/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7731 - loss: 0.6582\n",
      "Epoch 164/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7712 - loss: 0.6573\n",
      "Epoch 165/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7698 - loss: 0.6594\n",
      "Epoch 166/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7730 - loss: 0.6576\n",
      "Epoch 167/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7716 - loss: 0.6566\n",
      "Epoch 168/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7722 - loss: 0.6555\n",
      "Epoch 169/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7702 - loss: 0.6571\n",
      "Epoch 170/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7700 - loss: 0.6578\n",
      "Epoch 171/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7721 - loss: 0.6585\n",
      "Epoch 172/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7751 - loss: 0.6521\n",
      "Epoch 173/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7715 - loss: 0.6536\n",
      "Epoch 174/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7747 - loss: 0.6533\n",
      "Epoch 175/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7715 - loss: 0.6564\n",
      "Epoch 176/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7717 - loss: 0.6521\n",
      "Epoch 177/180\n",
      "44/44 - 0s - 9ms/step - accuracy: 0.7735 - loss: 0.6524\n",
      "Epoch 178/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7710 - loss: 0.6515\n",
      "Epoch 179/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7716 - loss: 0.6532\n",
      "Epoch 180/180\n",
      "44/44 - 0s - 8ms/step - accuracy: 0.7705 - loss: 0.6496\n",
      "WARNING:tensorflow:5 out of the last 21 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017C5E7CAE80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11/11 - 1s - 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "Epoch 1/180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "| \u001b[30m8         | \u001b[30mnan       | \u001b[30m2.799     | \u001b[30m297.6     | \u001b[30m0.7296    | \u001b[30m0.1913    | \u001b[30m179.7     | \u001b[30m1.944     | \u001b[30m1.12      | \u001b[30m1.713     | \u001b[30m0.07632   | \u001b[30m32.45     | \u001b[30m0.771     | \u001b[30m3.457     |\n",
      "Epoch 1/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 32), dtype=float32, path=sequential_36/conv1d_36/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 32), dtype=float32, path=sequential_37/conv1d_37/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 32), dtype=float32, path=sequential_38/conv1d_38/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 32), dtype=float32, path=sequential_39/conv1d_39/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 4s - 90ms/step - accuracy: 0.5247 - loss: 4.5057\n",
      "Epoch 2/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6243 - loss: 1.1173\n",
      "Epoch 3/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6217 - loss: 1.0677\n",
      "Epoch 4/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6274 - loss: 1.0228\n",
      "Epoch 5/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6403 - loss: 1.0003\n",
      "Epoch 6/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6411 - loss: 0.9841\n",
      "Epoch 7/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6366 - loss: 0.9858\n",
      "Epoch 8/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6491 - loss: 0.9577\n",
      "Epoch 9/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6576 - loss: 0.9410\n",
      "Epoch 10/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6726 - loss: 0.9223\n",
      "Epoch 11/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6861 - loss: 0.8779\n",
      "Epoch 12/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.6995 - loss: 0.8412\n",
      "Epoch 13/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.7029 - loss: 0.8274\n",
      "Epoch 14/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.7035 - loss: 0.8111\n",
      "Epoch 15/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.7169 - loss: 0.7946\n",
      "Epoch 16/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.7151 - loss: 0.7934\n",
      "Epoch 17/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.7138 - loss: 0.7889\n",
      "Epoch 18/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.7240 - loss: 0.7784\n",
      "Epoch 19/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.7242 - loss: 0.7577\n",
      "Epoch 20/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.7163 - loss: 0.7788\n",
      "Epoch 21/26\n",
      "40/40 - 0s - 6ms/step - accuracy: 0.7207 - loss: 0.7693\n",
      "Epoch 22/26\n",
      "40/40 - 0s - 7ms/step - accuracy: 0.7399 - loss: 0.7459\n",
      "Epoch 23/26\n",
      "40/40 - 0s - 7ms/step - accuracy: 0.7433 - loss: 0.7424\n",
      "Epoch 24/26\n",
      "40/40 - 0s - 7ms/step - accuracy: 0.7498 - loss: 0.7232\n",
      "Epoch 25/26\n",
      "40/40 - 0s - 7ms/step - accuracy: 0.7562 - loss: 0.6980\n",
      "Epoch 26/26\n",
      "40/40 - 0s - 8ms/step - accuracy: 0.7457 - loss: 0.7362\n",
      "10/10 - 0s - 33ms/step\n",
      "Epoch 1/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 20), dtype=float32, path=sequential_41/conv1d_41/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 20), dtype=float32, path=sequential_42/conv1d_42/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 20), dtype=float32, path=sequential_43/conv1d_43/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 20), dtype=float32, path=sequential_44/conv1d_44/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m9         | \u001b[30mnan       | \u001b[30m4.705     | \u001b[30m328.3     | \u001b[30m0.02542   | \u001b[30m0.03237   | \u001b[30m25.66     | \u001b[30m2.273     | \u001b[30m1.314     | \u001b[30m1.509     | \u001b[30m0.09085   | \u001b[30m19.97     | \u001b[30m0.4104    | \u001b[30m5.289     |\n",
      "Epoch 1/187\n",
      "58/58 - 3s - 55ms/step - accuracy: 0.6278 - loss: 1.1944\n",
      "Epoch 2/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.6677 - loss: 1.0028\n",
      "Epoch 3/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7117 - loss: 0.9080\n",
      "Epoch 4/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7162 - loss: 0.8663\n",
      "Epoch 5/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7259 - loss: 0.8258\n",
      "Epoch 6/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7347 - loss: 0.7823\n",
      "Epoch 7/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7432 - loss: 0.7474\n",
      "Epoch 8/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7516 - loss: 0.7268\n",
      "Epoch 9/187\n",
      "58/58 - 0s - 6ms/step - accuracy: 0.7593 - loss: 0.7083\n",
      "Epoch 10/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7624 - loss: 0.6885\n",
      "Epoch 11/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7652 - loss: 0.6808\n",
      "Epoch 12/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7707 - loss: 0.6674\n",
      "Epoch 13/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7744 - loss: 0.6561\n",
      "Epoch 14/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7728 - loss: 0.6566\n",
      "Epoch 15/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7754 - loss: 0.6442\n",
      "Epoch 16/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7733 - loss: 0.6422\n",
      "Epoch 17/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7779 - loss: 0.6342\n",
      "Epoch 18/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7789 - loss: 0.6303\n",
      "Epoch 19/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7833 - loss: 0.6143\n",
      "Epoch 20/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7824 - loss: 0.6165\n",
      "Epoch 21/187\n",
      "58/58 - 0s - 6ms/step - accuracy: 0.7849 - loss: 0.6094\n",
      "Epoch 22/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7836 - loss: 0.6065\n",
      "Epoch 23/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7850 - loss: 0.6000\n",
      "Epoch 24/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7853 - loss: 0.5977\n",
      "Epoch 25/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7921 - loss: 0.5878\n",
      "Epoch 26/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7896 - loss: 0.5875\n",
      "Epoch 27/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7887 - loss: 0.5874\n",
      "Epoch 28/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7932 - loss: 0.5772\n",
      "Epoch 29/187\n",
      "58/58 - 0s - 8ms/step - accuracy: 0.7912 - loss: 0.5738\n",
      "Epoch 30/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7939 - loss: 0.5699\n",
      "Epoch 31/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7919 - loss: 0.5726\n",
      "Epoch 32/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7957 - loss: 0.5683\n",
      "Epoch 33/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7954 - loss: 0.5658\n",
      "Epoch 34/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7989 - loss: 0.5571\n",
      "Epoch 35/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7996 - loss: 0.5525\n",
      "Epoch 36/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8007 - loss: 0.5522\n",
      "Epoch 37/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8019 - loss: 0.5497\n",
      "Epoch 38/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7997 - loss: 0.5516\n",
      "Epoch 39/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8002 - loss: 0.5466\n",
      "Epoch 40/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.7976 - loss: 0.5464\n",
      "Epoch 41/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8010 - loss: 0.5422\n",
      "Epoch 42/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8069 - loss: 0.5350\n",
      "Epoch 43/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8039 - loss: 0.5310\n",
      "Epoch 44/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8059 - loss: 0.5340\n",
      "Epoch 45/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8077 - loss: 0.5299\n",
      "Epoch 46/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8066 - loss: 0.5286\n",
      "Epoch 47/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8071 - loss: 0.5205\n",
      "Epoch 48/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8054 - loss: 0.5269\n",
      "Epoch 49/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8103 - loss: 0.5199\n",
      "Epoch 50/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8062 - loss: 0.5231\n",
      "Epoch 51/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8126 - loss: 0.5175\n",
      "Epoch 52/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8126 - loss: 0.5131\n",
      "Epoch 53/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8143 - loss: 0.5063\n",
      "Epoch 54/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8130 - loss: 0.5088\n",
      "Epoch 55/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8129 - loss: 0.5093\n",
      "Epoch 56/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8171 - loss: 0.5055\n",
      "Epoch 57/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8127 - loss: 0.5081\n",
      "Epoch 58/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8144 - loss: 0.5080\n",
      "Epoch 59/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8164 - loss: 0.4992\n",
      "Epoch 60/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8163 - loss: 0.4989\n",
      "Epoch 61/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8163 - loss: 0.4979\n",
      "Epoch 62/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8185 - loss: 0.4926\n",
      "Epoch 63/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8153 - loss: 0.4951\n",
      "Epoch 64/187\n",
      "58/58 - 0s - 8ms/step - accuracy: 0.8186 - loss: 0.4929\n",
      "Epoch 65/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8199 - loss: 0.4904\n",
      "Epoch 66/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8211 - loss: 0.4843\n",
      "Epoch 67/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8200 - loss: 0.4860\n",
      "Epoch 68/187\n",
      "58/58 - 0s - 8ms/step - accuracy: 0.8209 - loss: 0.4830\n",
      "Epoch 69/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8200 - loss: 0.4881\n",
      "Epoch 70/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8206 - loss: 0.4830\n",
      "Epoch 71/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8215 - loss: 0.4807\n",
      "Epoch 72/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8247 - loss: 0.4733\n",
      "Epoch 73/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8252 - loss: 0.4751\n",
      "Epoch 74/187\n",
      "58/58 - 0s - 8ms/step - accuracy: 0.8273 - loss: 0.4681\n",
      "Epoch 75/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8221 - loss: 0.4797\n",
      "Epoch 76/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8258 - loss: 0.4681\n",
      "Epoch 77/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8273 - loss: 0.4684\n",
      "Epoch 78/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8270 - loss: 0.4674\n",
      "Epoch 79/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8253 - loss: 0.4668\n",
      "Epoch 80/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8319 - loss: 0.4570\n",
      "Epoch 81/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8256 - loss: 0.4624\n",
      "Epoch 82/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8273 - loss: 0.4617\n",
      "Epoch 83/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8288 - loss: 0.4593\n",
      "Epoch 84/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8270 - loss: 0.4590\n",
      "Epoch 85/187\n",
      "58/58 - 0s - 6ms/step - accuracy: 0.8279 - loss: 0.4591\n",
      "Epoch 86/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8307 - loss: 0.4555\n",
      "Epoch 87/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8329 - loss: 0.4488\n",
      "Epoch 88/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8326 - loss: 0.4550\n",
      "Epoch 89/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8311 - loss: 0.4518\n",
      "Epoch 90/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8329 - loss: 0.4508\n",
      "Epoch 91/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8317 - loss: 0.4528\n",
      "Epoch 92/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8351 - loss: 0.4424\n",
      "Epoch 93/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8312 - loss: 0.4516\n",
      "Epoch 94/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8340 - loss: 0.4427\n",
      "Epoch 95/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8384 - loss: 0.4372\n",
      "Epoch 96/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8371 - loss: 0.4401\n",
      "Epoch 97/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8340 - loss: 0.4413\n",
      "Epoch 98/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8317 - loss: 0.4465\n",
      "Epoch 99/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8337 - loss: 0.4422\n",
      "Epoch 100/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8341 - loss: 0.4425\n",
      "Epoch 101/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8349 - loss: 0.4375\n",
      "Epoch 102/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8349 - loss: 0.4411\n",
      "Epoch 103/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8395 - loss: 0.4300\n",
      "Epoch 104/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8407 - loss: 0.4294\n",
      "Epoch 105/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8357 - loss: 0.4375\n",
      "Epoch 106/187\n",
      "58/58 - 0s - 8ms/step - accuracy: 0.8396 - loss: 0.4324\n",
      "Epoch 107/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8396 - loss: 0.4311\n",
      "Epoch 108/187\n",
      "58/58 - 0s - 8ms/step - accuracy: 0.8375 - loss: 0.4271\n",
      "Epoch 109/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8398 - loss: 0.4320\n",
      "Epoch 110/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8399 - loss: 0.4262\n",
      "Epoch 111/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8383 - loss: 0.4302\n",
      "Epoch 112/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8373 - loss: 0.4332\n",
      "Epoch 113/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8403 - loss: 0.4236\n",
      "Epoch 114/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8406 - loss: 0.4286\n",
      "Epoch 115/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8418 - loss: 0.4225\n",
      "Epoch 116/187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 - 0s - 7ms/step - accuracy: 0.8453 - loss: 0.4169\n",
      "Epoch 117/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8447 - loss: 0.4209\n",
      "Epoch 118/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8415 - loss: 0.4254\n",
      "Epoch 119/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8421 - loss: 0.4220\n",
      "Epoch 120/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8431 - loss: 0.4199\n",
      "Epoch 121/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8376 - loss: 0.4265\n",
      "Epoch 122/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8439 - loss: 0.4176\n",
      "Epoch 123/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8431 - loss: 0.4146\n",
      "Epoch 124/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8452 - loss: 0.4170\n",
      "Epoch 125/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8457 - loss: 0.4157\n",
      "Epoch 126/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8440 - loss: 0.4205\n",
      "Epoch 127/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8420 - loss: 0.4133\n",
      "Epoch 128/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8477 - loss: 0.4060\n",
      "Epoch 129/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8459 - loss: 0.4149\n",
      "Epoch 130/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8476 - loss: 0.4099\n",
      "Epoch 131/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8484 - loss: 0.4045\n",
      "Epoch 132/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8452 - loss: 0.4126\n",
      "Epoch 133/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8471 - loss: 0.4120\n",
      "Epoch 134/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8476 - loss: 0.4078\n",
      "Epoch 135/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8468 - loss: 0.4084\n",
      "Epoch 136/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8474 - loss: 0.4036\n",
      "Epoch 137/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8473 - loss: 0.4070\n",
      "Epoch 138/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8453 - loss: 0.4057\n",
      "Epoch 139/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8451 - loss: 0.4112\n",
      "Epoch 140/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8480 - loss: 0.4002\n",
      "Epoch 141/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8468 - loss: 0.4073\n",
      "Epoch 142/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8488 - loss: 0.4005\n",
      "Epoch 143/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8500 - loss: 0.3991\n",
      "Epoch 144/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8497 - loss: 0.4021\n",
      "Epoch 145/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8521 - loss: 0.3976\n",
      "Epoch 146/187\n",
      "58/58 - 0s - 8ms/step - accuracy: 0.8509 - loss: 0.3978\n",
      "Epoch 147/187\n",
      "58/58 - 0s - 8ms/step - accuracy: 0.8472 - loss: 0.3995\n",
      "Epoch 148/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8495 - loss: 0.4021\n",
      "Epoch 149/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8526 - loss: 0.3919\n",
      "Epoch 150/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8498 - loss: 0.3982\n",
      "Epoch 151/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8517 - loss: 0.3948\n",
      "Epoch 152/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8516 - loss: 0.3974\n",
      "Epoch 153/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8533 - loss: 0.3932\n",
      "Epoch 154/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8474 - loss: 0.3988\n",
      "Epoch 155/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8543 - loss: 0.3911\n",
      "Epoch 156/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8529 - loss: 0.3921\n",
      "Epoch 157/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8500 - loss: 0.3975\n",
      "Epoch 158/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8501 - loss: 0.3953\n",
      "Epoch 159/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8545 - loss: 0.3861\n",
      "Epoch 160/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8525 - loss: 0.3912\n",
      "Epoch 161/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8526 - loss: 0.3888\n",
      "Epoch 162/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8529 - loss: 0.3880\n",
      "Epoch 163/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8542 - loss: 0.3831\n",
      "Epoch 164/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8538 - loss: 0.3859\n",
      "Epoch 165/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8547 - loss: 0.3880\n",
      "Epoch 166/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8558 - loss: 0.3840\n",
      "Epoch 167/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8545 - loss: 0.3874\n",
      "Epoch 168/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8516 - loss: 0.3921\n",
      "Epoch 169/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8535 - loss: 0.3823\n",
      "Epoch 170/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8555 - loss: 0.3802\n",
      "Epoch 171/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8523 - loss: 0.3894\n",
      "Epoch 172/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8555 - loss: 0.3827\n",
      "Epoch 173/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8551 - loss: 0.3836\n",
      "Epoch 174/187\n",
      "58/58 - 0s - 6ms/step - accuracy: 0.8559 - loss: 0.3862\n",
      "Epoch 175/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8564 - loss: 0.3761\n",
      "Epoch 176/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8524 - loss: 0.3861\n",
      "Epoch 177/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8604 - loss: 0.3768\n",
      "Epoch 178/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8590 - loss: 0.3825\n",
      "Epoch 179/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8586 - loss: 0.3829\n",
      "Epoch 180/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8582 - loss: 0.3792\n",
      "Epoch 181/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8569 - loss: 0.3757\n",
      "Epoch 182/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8606 - loss: 0.3716\n",
      "Epoch 183/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8569 - loss: 0.3794\n",
      "Epoch 184/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8615 - loss: 0.3688\n",
      "Epoch 185/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8543 - loss: 0.3816\n",
      "Epoch 186/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8610 - loss: 0.3651\n",
      "Epoch 187/187\n",
      "58/58 - 0s - 7ms/step - accuracy: 0.8604 - loss: 0.3761\n",
      "15/15 - 0s - 29ms/step\n",
      "Epoch 1/187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(3, 9, 17), dtype=float32, path=sequential_46/conv1d_46/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(3, 9, 17), dtype=float32, path=sequential_47/conv1d_47/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(3, 9, 17), dtype=float32, path=sequential_48/conv1d_48/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(3, 9, 17), dtype=float32, path=sequential_49/conv1d_49/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m10        | \u001b[30mnan       | \u001b[30m2.059     | \u001b[30m223.1     | \u001b[30m0.2898    | \u001b[30m0.04837   | \u001b[30m187.3     | \u001b[30m2.616     | \u001b[30m1.633     | \u001b[30m1.871     | \u001b[30m0.08056   | \u001b[30m17.46     | \u001b[30m0.8926    | \u001b[30m3.775     |\n",
      "Epoch 1/61\n",
      "28/28 - 3s - 103ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 2/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 3/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 4/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 5/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 6/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 7/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 8/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 9/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 10/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 11/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 12/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 13/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 14/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 15/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 16/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 17/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 18/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 19/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 20/61\n",
      "28/28 - 0s - 8ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 21/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 22/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 23/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 24/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 25/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 26/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 27/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 28/61\n",
      "28/28 - 0s - 8ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 29/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 30/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 31/61\n",
      "28/28 - 0s - 10ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 32/61\n",
      "28/28 - 0s - 10ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 33/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 34/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 35/61\n",
      "28/28 - 0s - 10ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 36/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 37/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 38/61\n",
      "28/28 - 0s - 10ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 39/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 40/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 41/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 42/61\n",
      "28/28 - 0s - 10ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 43/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 44/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 45/61\n",
      "28/28 - 0s - 10ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 46/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 47/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 48/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 49/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 50/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 51/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 52/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 53/61\n",
      "28/28 - 0s - 10ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 54/61\n",
      "28/28 - 0s - 10ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 55/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 56/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 57/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 58/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 59/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 60/61\n",
      "28/28 - 0s - 10ms/step - accuracy: 0.6423 - loss: nan\n",
      "Epoch 61/61\n",
      "28/28 - 0s - 9ms/step - accuracy: 0.6423 - loss: nan\n",
      "7/7 - 0s - 48ms/step\n",
      "Epoch 1/61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 30), dtype=float32, path=sequential_51/conv1d_51/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 30), dtype=float32, path=sequential_52/conv1d_52/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 30), dtype=float32, path=sequential_53/conv1d_53/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 30), dtype=float32, path=sequential_54/conv1d_54/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m11        | \u001b[30mnan       | \u001b[30m7.267     | \u001b[30m468.8     | \u001b[30m0.318     | \u001b[30m0.03302   | \u001b[30m61.03     | \u001b[30m1.854     | \u001b[30m1.818     | \u001b[30m1.861     | \u001b[30m0.001688  | \u001b[30m30.43     | \u001b[30m0.4174    | \u001b[30m1.555     |\n",
      "Epoch 1/113\n",
      "43/43 - 3s - 61ms/step - accuracy: 0.6044 - loss: 1.5147\n",
      "Epoch 2/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6240 - loss: 1.1614\n",
      "Epoch 3/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6352 - loss: 1.0634\n",
      "Epoch 4/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6416 - loss: 1.0166\n",
      "Epoch 5/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6478 - loss: 0.9960\n",
      "Epoch 6/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6523 - loss: 0.9774\n",
      "Epoch 7/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6649 - loss: 0.9470\n",
      "Epoch 8/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6647 - loss: 0.9345\n",
      "Epoch 9/113\n",
      "43/43 - 0s - 8ms/step - accuracy: 0.6657 - loss: 0.9209\n",
      "Epoch 10/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6733 - loss: 0.9007\n",
      "Epoch 11/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6736 - loss: 0.8950\n",
      "Epoch 12/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6780 - loss: 0.8726\n",
      "Epoch 13/113\n",
      "43/43 - 0s - 8ms/step - accuracy: 0.6879 - loss: 0.8576\n",
      "Epoch 14/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.6969 - loss: 0.8529\n",
      "Epoch 15/113\n",
      "43/43 - 0s - 8ms/step - accuracy: 0.6958 - loss: 0.8479\n",
      "Epoch 16/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7039 - loss: 0.8366\n",
      "Epoch 17/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7099 - loss: 0.8197\n",
      "Epoch 18/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7111 - loss: 0.8222\n",
      "Epoch 19/113\n",
      "43/43 - 0s - 8ms/step - accuracy: 0.7209 - loss: 0.8040\n",
      "Epoch 20/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7189 - loss: 0.8065\n",
      "Epoch 21/113\n",
      "43/43 - 0s - 8ms/step - accuracy: 0.7175 - loss: 0.8029\n",
      "Epoch 22/113\n",
      "43/43 - 0s - 8ms/step - accuracy: 0.7138 - loss: 0.7985\n",
      "Epoch 23/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7137 - loss: 0.7995\n",
      "Epoch 24/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7213 - loss: 0.7965\n",
      "Epoch 25/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7210 - loss: 0.7891\n",
      "Epoch 26/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7197 - loss: 0.7848\n",
      "Epoch 27/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7257 - loss: 0.7786\n",
      "Epoch 28/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7253 - loss: 0.7783\n",
      "Epoch 29/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7272 - loss: 0.7695\n",
      "Epoch 30/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7301 - loss: 0.7703\n",
      "Epoch 31/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7304 - loss: 0.7637\n",
      "Epoch 32/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7368 - loss: 0.7522\n",
      "Epoch 33/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7333 - loss: 0.7541\n",
      "Epoch 34/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7365 - loss: 0.7463\n",
      "Epoch 35/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7375 - loss: 0.7476\n",
      "Epoch 36/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7376 - loss: 0.7490\n",
      "Epoch 37/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7377 - loss: 0.7452\n",
      "Epoch 38/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7333 - loss: 0.7572\n",
      "Epoch 39/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7355 - loss: 0.7510\n",
      "Epoch 40/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7381 - loss: 0.7456\n",
      "Epoch 41/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7328 - loss: 0.7465\n",
      "Epoch 42/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7420 - loss: 0.7332\n",
      "Epoch 43/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7439 - loss: 0.7368\n",
      "Epoch 44/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7411 - loss: 0.7386\n",
      "Epoch 45/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7420 - loss: 0.7421\n",
      "Epoch 46/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7426 - loss: 0.7290\n",
      "Epoch 47/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7325 - loss: 0.7394\n",
      "Epoch 48/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7421 - loss: 0.7262\n",
      "Epoch 49/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7394 - loss: 0.7228\n",
      "Epoch 50/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7457 - loss: 0.7185\n",
      "Epoch 51/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7502 - loss: 0.7204\n",
      "Epoch 52/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7458 - loss: 0.7110\n",
      "Epoch 53/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7447 - loss: 0.7278\n",
      "Epoch 54/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7462 - loss: 0.7099\n",
      "Epoch 55/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7350 - loss: 0.7274\n",
      "Epoch 56/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7502 - loss: 0.7008\n",
      "Epoch 57/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7425 - loss: 0.7097\n",
      "Epoch 58/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7502 - loss: 0.7053\n",
      "Epoch 59/113\n",
      "43/43 - 0s - 6ms/step - accuracy: 0.7547 - loss: 0.6963\n",
      "Epoch 60/113\n",
      "43/43 - 0s - 8ms/step - accuracy: 0.7529 - loss: 0.6957\n",
      "Epoch 61/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7481 - loss: 0.6993\n",
      "Epoch 62/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7527 - loss: 0.6996\n",
      "Epoch 63/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7482 - loss: 0.7006\n",
      "Epoch 64/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7425 - loss: 0.7072\n",
      "Epoch 65/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7474 - loss: 0.7048\n",
      "Epoch 66/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7590 - loss: 0.6840\n",
      "Epoch 67/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7489 - loss: 0.7031\n",
      "Epoch 68/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7543 - loss: 0.6911\n",
      "Epoch 69/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7563 - loss: 0.6928\n",
      "Epoch 70/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7586 - loss: 0.6828\n",
      "Epoch 71/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7455 - loss: 0.7040\n",
      "Epoch 72/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7532 - loss: 0.6836\n",
      "Epoch 73/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7586 - loss: 0.6758\n",
      "Epoch 74/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7568 - loss: 0.6794\n",
      "Epoch 75/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7619 - loss: 0.6717\n",
      "Epoch 76/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7575 - loss: 0.6747\n",
      "Epoch 77/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7593 - loss: 0.6767\n",
      "Epoch 78/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7601 - loss: 0.6759\n",
      "Epoch 79/113\n",
      "43/43 - 0s - 6ms/step - accuracy: 0.7651 - loss: 0.6565\n",
      "Epoch 80/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7526 - loss: 0.6781\n",
      "Epoch 81/113\n",
      "43/43 - 0s - 6ms/step - accuracy: 0.7602 - loss: 0.6721\n",
      "Epoch 82/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7656 - loss: 0.6681\n",
      "Epoch 83/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7691 - loss: 0.6514\n",
      "Epoch 84/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7622 - loss: 0.6669\n",
      "Epoch 85/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7583 - loss: 0.6645\n",
      "Epoch 86/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7580 - loss: 0.6613\n",
      "Epoch 87/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7614 - loss: 0.6626\n",
      "Epoch 88/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7662 - loss: 0.6539\n",
      "Epoch 89/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7557 - loss: 0.6661\n",
      "Epoch 90/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7677 - loss: 0.6511\n",
      "Epoch 91/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7670 - loss: 0.6393\n",
      "Epoch 92/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7602 - loss: 0.6610\n",
      "Epoch 93/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7691 - loss: 0.6424\n",
      "Epoch 94/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7712 - loss: 0.6431\n",
      "Epoch 95/113\n",
      "43/43 - 0s - 6ms/step - accuracy: 0.7675 - loss: 0.6499\n",
      "Epoch 96/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7610 - loss: 0.6501\n",
      "Epoch 97/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7696 - loss: 0.6396\n",
      "Epoch 98/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7693 - loss: 0.6499\n",
      "Epoch 99/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7737 - loss: 0.6310\n",
      "Epoch 100/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7681 - loss: 0.6460\n",
      "Epoch 101/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7701 - loss: 0.6406\n",
      "Epoch 102/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7699 - loss: 0.6481\n",
      "Epoch 103/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7705 - loss: 0.6433\n",
      "Epoch 104/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7698 - loss: 0.6467\n",
      "Epoch 105/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7677 - loss: 0.6440\n",
      "Epoch 106/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7753 - loss: 0.6324\n",
      "Epoch 107/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7720 - loss: 0.6383\n",
      "Epoch 108/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7754 - loss: 0.6299\n",
      "Epoch 109/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7760 - loss: 0.6263\n",
      "Epoch 110/113\n",
      "43/43 - 0s - 6ms/step - accuracy: 0.7749 - loss: 0.6319\n",
      "Epoch 111/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7737 - loss: 0.6222\n",
      "Epoch 112/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7761 - loss: 0.6269\n",
      "Epoch 113/113\n",
      "43/43 - 0s - 7ms/step - accuracy: 0.7770 - loss: 0.6253\n",
      "11/11 - 0s - 32ms/step\n",
      "Epoch 1/113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 20), dtype=float32, path=sequential_56/conv1d_56/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 20), dtype=float32, path=sequential_57/conv1d_57/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 20), dtype=float32, path=sequential_58/conv1d_58/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 20), dtype=float32, path=sequential_59/conv1d_59/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m12        | \u001b[30mnan       | \u001b[30m1.079     | \u001b[30m301.3     | \u001b[30m0.9429    | \u001b[30m0.09696   | \u001b[30m113.4     | \u001b[30m2.406     | \u001b[30m1.364     | \u001b[30m1.972     | \u001b[30m0.09628   | \u001b[30m20.07     | \u001b[30m0.4972    | \u001b[30m2.106     |\n",
      "Epoch 1/29\n",
      "61/61 - 3s - 57ms/step - accuracy: 0.6524 - loss: 1.0338\n",
      "Epoch 2/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7075 - loss: 0.8324\n",
      "Epoch 3/29\n",
      "61/61 - 0s - 7ms/step - accuracy: 0.7165 - loss: 0.7955\n",
      "Epoch 4/29\n",
      "61/61 - 0s - 7ms/step - accuracy: 0.7249 - loss: 0.7705\n",
      "Epoch 5/29\n",
      "61/61 - 0s - 7ms/step - accuracy: 0.7402 - loss: 0.7336\n",
      "Epoch 6/29\n",
      "61/61 - 0s - 7ms/step - accuracy: 0.7436 - loss: 0.7272\n",
      "Epoch 7/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7528 - loss: 0.6999\n",
      "Epoch 8/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7453 - loss: 0.7030\n",
      "Epoch 9/29\n",
      "61/61 - 0s - 7ms/step - accuracy: 0.7520 - loss: 0.6983\n",
      "Epoch 10/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7595 - loss: 0.6768\n",
      "Epoch 11/29\n",
      "61/61 - 0s - 7ms/step - accuracy: 0.7610 - loss: 0.6585\n",
      "Epoch 12/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7591 - loss: 0.6719\n",
      "Epoch 13/29\n",
      "61/61 - 0s - 7ms/step - accuracy: 0.7738 - loss: 0.6437\n",
      "Epoch 14/29\n",
      "61/61 - 0s - 7ms/step - accuracy: 0.7796 - loss: 0.6220\n",
      "Epoch 15/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7817 - loss: 0.6159\n",
      "Epoch 16/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7825 - loss: 0.6060\n",
      "Epoch 17/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7891 - loss: 0.5877\n",
      "Epoch 18/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7958 - loss: 0.5773\n",
      "Epoch 19/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.7973 - loss: 0.5750\n",
      "Epoch 20/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.8005 - loss: 0.5598\n",
      "Epoch 21/29\n",
      "61/61 - 1s - 8ms/step - accuracy: 0.8045 - loss: 0.5528\n",
      "Epoch 22/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.8101 - loss: 0.5364\n",
      "Epoch 23/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.8124 - loss: 0.5365\n",
      "Epoch 24/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.8130 - loss: 0.5212\n",
      "Epoch 25/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.8168 - loss: 0.5212\n",
      "Epoch 26/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.8208 - loss: 0.5107\n",
      "Epoch 27/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.8281 - loss: 0.5004\n",
      "Epoch 28/29\n",
      "61/61 - 0s - 7ms/step - accuracy: 0.8224 - loss: 0.5022\n",
      "Epoch 29/29\n",
      "61/61 - 0s - 8ms/step - accuracy: 0.8289 - loss: 0.4910\n",
      "16/16 - 0s - 25ms/step\n",
      "Epoch 1/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29\n",
      "Epoch 1/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 30), dtype=float32, path=sequential_61/conv1d_61/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 30), dtype=float32, path=sequential_62/conv1d_62/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 30), dtype=float32, path=sequential_63/conv1d_63/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 30), dtype=float32, path=sequential_64/conv1d_64/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m13        | \u001b[30mnan       | \u001b[30m2.564     | \u001b[30m211.1     | \u001b[30m0.6096    | \u001b[30m0.1508    | \u001b[30m29.27     | \u001b[30m1.557     | \u001b[30m1.908     | \u001b[30m1.24      | \u001b[30m0.01534   | \u001b[30m29.58     | \u001b[30m0.9857    | \u001b[30m1.694     |\n",
      "Epoch 1/86\n",
      "31/31 - 5s - 153ms/step - accuracy: 0.6244 - loss: 1.2123\n",
      "Epoch 2/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7337 - loss: 0.7840\n",
      "Epoch 3/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7520 - loss: 0.7268\n",
      "Epoch 4/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7594 - loss: 0.6926\n",
      "Epoch 5/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7575 - loss: 0.6824\n",
      "Epoch 6/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.7778 - loss: 0.6322\n",
      "Epoch 7/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7831 - loss: 0.6049\n",
      "Epoch 8/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7781 - loss: 0.6288\n",
      "Epoch 9/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7799 - loss: 0.6122\n",
      "Epoch 10/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7850 - loss: 0.5993\n",
      "Epoch 11/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7887 - loss: 0.5905\n",
      "Epoch 12/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7976 - loss: 0.5597\n",
      "Epoch 13/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8083 - loss: 0.5249\n",
      "Epoch 14/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8011 - loss: 0.5471\n",
      "Epoch 15/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8009 - loss: 0.5505\n",
      "Epoch 16/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8045 - loss: 0.5360\n",
      "Epoch 17/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8197 - loss: 0.4879\n",
      "Epoch 18/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8141 - loss: 0.5154\n",
      "Epoch 19/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8103 - loss: 0.5189\n",
      "Epoch 20/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8167 - loss: 0.5086\n",
      "Epoch 21/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7958 - loss: 0.5550\n",
      "Epoch 22/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8245 - loss: 0.4873\n",
      "Epoch 23/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8060 - loss: 0.5305\n",
      "Epoch 24/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8198 - loss: 0.4993\n",
      "Epoch 25/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8302 - loss: 0.4717\n",
      "Epoch 26/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8289 - loss: 0.4814\n",
      "Epoch 27/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8258 - loss: 0.4922\n",
      "Epoch 28/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8367 - loss: 0.4438\n",
      "Epoch 29/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8575 - loss: 0.4012\n",
      "Epoch 30/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8336 - loss: 0.4680\n",
      "Epoch 31/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8538 - loss: 0.4018\n",
      "Epoch 32/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8483 - loss: 0.4108\n",
      "Epoch 33/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8200 - loss: 0.5050\n",
      "Epoch 34/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8530 - loss: 0.4102\n",
      "Epoch 35/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8530 - loss: 0.4044\n",
      "Epoch 36/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8401 - loss: 0.4552\n",
      "Epoch 37/86\n",
      "31/31 - 0s - 12ms/step - accuracy: 0.8491 - loss: 0.4261\n",
      "Epoch 38/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8514 - loss: 0.4217\n",
      "Epoch 39/86\n",
      "31/31 - 0s - 12ms/step - accuracy: 0.8809 - loss: 0.3330\n",
      "Epoch 40/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8661 - loss: 0.3819\n",
      "Epoch 41/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8545 - loss: 0.4068\n",
      "Epoch 42/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8886 - loss: 0.3041\n",
      "Epoch 43/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8380 - loss: 0.4529\n",
      "Epoch 44/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8552 - loss: 0.3979\n",
      "Epoch 45/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8673 - loss: 0.3662\n",
      "Epoch 46/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8863 - loss: 0.3072\n",
      "Epoch 47/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8761 - loss: 0.3368\n",
      "Epoch 48/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8767 - loss: 0.3527\n",
      "Epoch 49/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8293 - loss: 0.4952\n",
      "Epoch 50/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8737 - loss: 0.3432\n",
      "Epoch 51/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8577 - loss: 0.4025\n",
      "Epoch 52/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8749 - loss: 0.3615\n",
      "Epoch 53/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8771 - loss: 0.3487\n",
      "Epoch 54/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8950 - loss: 0.2859\n",
      "Epoch 55/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.9153 - loss: 0.2355\n",
      "Epoch 56/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8883 - loss: 0.3194\n",
      "Epoch 57/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9085 - loss: 0.2570\n",
      "Epoch 58/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9006 - loss: 0.2781\n",
      "Epoch 59/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9055 - loss: 0.2622\n",
      "Epoch 60/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8977 - loss: 0.2849\n",
      "Epoch 61/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9153 - loss: 0.2341\n",
      "Epoch 62/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9188 - loss: 0.2274\n",
      "Epoch 63/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8845 - loss: 0.3292\n",
      "Epoch 64/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8964 - loss: 0.2989\n",
      "Epoch 65/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.7388 - loss: 0.7822\n",
      "Epoch 66/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8481 - loss: 0.4181\n",
      "Epoch 67/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8794 - loss: 0.3334\n",
      "Epoch 68/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9057 - loss: 0.2620\n",
      "Epoch 69/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8923 - loss: 0.3193\n",
      "Epoch 70/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9005 - loss: 0.2819\n",
      "Epoch 71/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9139 - loss: 0.2445\n",
      "Epoch 72/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.8966 - loss: 0.2915\n",
      "Epoch 73/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8979 - loss: 0.2925\n",
      "Epoch 74/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8851 - loss: 0.3436\n",
      "Epoch 75/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9179 - loss: 0.2365\n",
      "Epoch 76/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9238 - loss: 0.2146\n",
      "Epoch 77/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8854 - loss: 0.3592\n",
      "Epoch 78/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.9045 - loss: 0.2805\n",
      "Epoch 79/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9016 - loss: 0.3035\n",
      "Epoch 80/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8789 - loss: 0.3684\n",
      "Epoch 81/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8951 - loss: 0.3150\n",
      "Epoch 82/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.8926 - loss: 0.3135\n",
      "Epoch 83/86\n",
      "31/31 - 0s - 12ms/step - accuracy: 0.8657 - loss: 0.3879\n",
      "Epoch 84/86\n",
      "31/31 - 0s - 10ms/step - accuracy: 0.9046 - loss: 0.2548\n",
      "Epoch 85/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9244 - loss: 0.2173\n",
      "Epoch 86/86\n",
      "31/31 - 0s - 11ms/step - accuracy: 0.9269 - loss: 0.2225\n",
      "8/8 - 0s - 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/86\n",
      "Epoch 1/86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 43), dtype=float32, path=sequential_66/conv1d_66/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 43), dtype=float32, path=sequential_67/conv1d_67/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 43), dtype=float32, path=sequential_68/conv1d_68/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(2, 9, 43), dtype=float32, path=sequential_69/conv1d_69/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m14        | \u001b[30mnan       | \u001b[30m6.049     | \u001b[30m428.5     | \u001b[30m0.2376    | \u001b[30m0.2185    | \u001b[30m86.2      | \u001b[30m2.265     | \u001b[30m1.634     | \u001b[30m1.536     | \u001b[30m0.009939  | \u001b[30m43.41     | \u001b[30m0.3208    | \u001b[30m1.306     |\n",
      "Epoch 1/112\n",
      "35/35 - 5s - 134ms/step - accuracy: 0.6209 - loss: 1.2029\n",
      "Epoch 2/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7106 - loss: 0.8357\n",
      "Epoch 3/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7165 - loss: 0.8027\n",
      "Epoch 4/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7330 - loss: 0.7388\n",
      "Epoch 5/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7388 - loss: 0.7154\n",
      "Epoch 6/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7271 - loss: 0.7486\n",
      "Epoch 7/112\n",
      "35/35 - 0s - 10ms/step - accuracy: 0.7477 - loss: 0.7028\n",
      "Epoch 8/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7559 - loss: 0.6881\n",
      "Epoch 9/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7681 - loss: 0.6675\n",
      "Epoch 10/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7764 - loss: 0.6327\n",
      "Epoch 11/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.6760 - loss: 0.9199\n",
      "Epoch 12/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7152 - loss: 0.7725\n",
      "Epoch 13/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7309 - loss: 0.7355\n",
      "Epoch 14/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7369 - loss: 0.6941\n",
      "Epoch 15/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7336 - loss: 0.6888\n",
      "Epoch 16/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7338 - loss: 0.6983\n",
      "Epoch 17/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7501 - loss: 0.6534\n",
      "Epoch 18/112\n",
      "35/35 - 0s - 10ms/step - accuracy: 0.7544 - loss: 0.6541\n",
      "Epoch 19/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7369 - loss: 0.7135\n",
      "Epoch 20/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7490 - loss: 0.6686\n",
      "Epoch 21/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7547 - loss: 0.6332\n",
      "Epoch 22/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7547 - loss: 0.6515\n",
      "Epoch 23/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7631 - loss: 0.6323\n",
      "Epoch 24/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7491 - loss: 0.6785\n",
      "Epoch 25/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7637 - loss: 0.6189\n",
      "Epoch 26/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7649 - loss: 0.6089\n",
      "Epoch 27/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7730 - loss: 0.5966\n",
      "Epoch 28/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7708 - loss: 0.5939\n",
      "Epoch 29/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7670 - loss: 0.6124\n",
      "Epoch 30/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7563 - loss: 0.6416\n",
      "Epoch 31/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7578 - loss: 0.6447\n",
      "Epoch 32/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7698 - loss: 0.5954\n",
      "Epoch 33/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7797 - loss: 0.5714\n",
      "Epoch 34/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7270 - loss: 0.7177\n",
      "Epoch 35/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7683 - loss: 0.6124\n",
      "Epoch 36/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7799 - loss: 0.5795\n",
      "Epoch 37/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7543 - loss: 0.6618\n",
      "Epoch 38/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7608 - loss: 0.6083\n",
      "Epoch 39/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7780 - loss: 0.5822\n",
      "Epoch 40/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7790 - loss: 0.5638\n",
      "Epoch 41/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7804 - loss: 0.5724\n",
      "Epoch 42/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7674 - loss: 0.6502\n",
      "Epoch 43/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7548 - loss: 0.6320\n",
      "Epoch 44/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7818 - loss: 0.5799\n",
      "Epoch 45/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7789 - loss: 0.5894\n",
      "Epoch 46/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7655 - loss: 0.6096\n",
      "Epoch 47/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7712 - loss: 0.6007\n",
      "Epoch 48/112\n",
      "35/35 - 0s - 10ms/step - accuracy: 0.7685 - loss: 0.6320\n",
      "Epoch 49/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7744 - loss: 0.5941\n",
      "Epoch 50/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7522 - loss: 0.6801\n",
      "Epoch 51/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7758 - loss: 0.5935\n",
      "Epoch 52/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7599 - loss: 0.6218\n",
      "Epoch 53/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7788 - loss: 0.5766\n",
      "Epoch 54/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7717 - loss: 0.5903\n",
      "Epoch 55/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7614 - loss: 0.6336\n",
      "Epoch 56/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7822 - loss: 0.5890\n",
      "Epoch 57/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7734 - loss: 0.5784\n",
      "Epoch 58/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7783 - loss: 0.5721\n",
      "Epoch 59/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7768 - loss: 0.5845\n",
      "Epoch 60/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7637 - loss: 0.6318\n",
      "Epoch 61/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7726 - loss: 0.5946\n",
      "Epoch 62/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7806 - loss: 0.5818\n",
      "Epoch 63/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7693 - loss: 0.6037\n",
      "Epoch 64/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7484 - loss: 0.6520\n",
      "Epoch 65/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7554 - loss: 0.6296\n",
      "Epoch 66/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7883 - loss: 0.5487\n",
      "Epoch 67/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7800 - loss: 0.5643\n",
      "Epoch 68/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7749 - loss: 0.6121\n",
      "Epoch 69/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7802 - loss: 0.5820\n",
      "Epoch 70/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7723 - loss: 0.5767\n",
      "Epoch 71/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7740 - loss: 0.5837\n",
      "Epoch 72/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7708 - loss: 0.5991\n",
      "Epoch 73/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7863 - loss: 0.5641\n",
      "Epoch 74/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7864 - loss: 0.5714\n",
      "Epoch 75/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7852 - loss: 0.5725\n",
      "Epoch 76/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7777 - loss: 0.5794\n",
      "Epoch 77/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7751 - loss: 0.5802\n",
      "Epoch 78/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.6832 - loss: 0.8201\n",
      "Epoch 79/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7228 - loss: 0.7161\n",
      "Epoch 80/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7191 - loss: 0.7255\n",
      "Epoch 81/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7289 - loss: 0.6922\n",
      "Epoch 82/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7277 - loss: 0.7079\n",
      "Epoch 83/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7140 - loss: 0.7354\n",
      "Epoch 84/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7298 - loss: 0.7005\n",
      "Epoch 85/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7314 - loss: 0.7111\n",
      "Epoch 86/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7360 - loss: 0.6883\n",
      "Epoch 87/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7403 - loss: 0.6640\n",
      "Epoch 88/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7298 - loss: 0.7246\n",
      "Epoch 89/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7190 - loss: 0.7200\n",
      "Epoch 90/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7387 - loss: 0.6817\n",
      "Epoch 91/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7371 - loss: 0.7077\n",
      "Epoch 92/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7305 - loss: 0.7197\n",
      "Epoch 93/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7361 - loss: 0.7011\n",
      "Epoch 94/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7274 - loss: 0.7372\n",
      "Epoch 95/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7001 - loss: 0.7648\n",
      "Epoch 96/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7217 - loss: 0.7649\n",
      "Epoch 97/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.6881 - loss: 0.7917\n",
      "Epoch 98/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7137 - loss: 0.7354\n",
      "Epoch 99/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7085 - loss: 0.7542\n",
      "Epoch 100/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6871 - loss: 0.8514\n",
      "Epoch 101/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6769 - loss: 0.8564\n",
      "Epoch 102/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6947 - loss: 0.8083\n",
      "Epoch 103/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6985 - loss: 0.8168\n",
      "Epoch 104/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6765 - loss: 0.9039\n",
      "Epoch 105/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6790 - loss: 0.8740\n",
      "Epoch 106/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6775 - loss: 0.8781\n",
      "Epoch 107/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.7014 - loss: 0.8717\n",
      "Epoch 108/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6814 - loss: 0.8609\n",
      "Epoch 109/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6992 - loss: 0.8277\n",
      "Epoch 110/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6857 - loss: 0.9201\n",
      "Epoch 111/112\n",
      "35/35 - 0s - 8ms/step - accuracy: 0.7049 - loss: 0.8600\n",
      "Epoch 112/112\n",
      "35/35 - 0s - 9ms/step - accuracy: 0.6857 - loss: 0.8738\n",
      "9/9 - 0s - 41ms/step\n",
      "Epoch 1/112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 25), dtype=float32, path=sequential_71/conv1d_71/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 25), dtype=float32, path=sequential_72/conv1d_72/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 25), dtype=float32, path=sequential_73/conv1d_73/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 228, in _check_variables_are_known\n",
      "    raise ValueError(\n",
      "ValueError: Unknown variable: <KerasVariable shape=(1, 9, 25), dtype=float32, path=sequential_74/conv1d_74/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[30m15        | \u001b[30mnan       | \u001b[30m0.367     | \u001b[30m377.3     | \u001b[30m0.6776    | \u001b[30m0.004976  | \u001b[30m112.2     | \u001b[30m1.453     | \u001b[30m1.645     | \u001b[30m1.174     | \u001b[30m0.0694    | \u001b[30m25.47     | \u001b[30m0.9367    | \u001b[30m0.9626    |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:369\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 369\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue)\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:40\u001b[0m, in \u001b[0;36mQueue.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueue is empty, no more objects to retrieve.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[0;32m     17\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(bay_area, params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m nn_opt\u001b[38;5;241m.\u001b[39mmaximize(init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:372\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m     util\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[1;32m--> 372\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[0;32m    373\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:264\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[1;34m(self, utility_function)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    263\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_constrained:\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams,\n\u001b[0;32m    267\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    252\u001b[0m     X,\n\u001b[0;32m    253\u001b[0m     y,\n\u001b[0;32m    254\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    255\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    256\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    257\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1318\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[1;32m-> 1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1328\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1328\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1329\u001b[0m         y,\n\u001b[0;32m   1330\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1331\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1332\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1333\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1334\u001b[0m         input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1335\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1336\u001b[0m     )\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1065\u001b[0m         array,\n\u001b[0;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1069\u001b[0m     )\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    124\u001b[0m     X,\n\u001b[0;32m    125\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    126\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    127\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    128\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    129\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    130\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "params ={\n",
    "    'neurons': (10, 50),            # Reduced upper limit\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 9), \n",
    "    'optimizer':(0,7), \n",
    "    'learning_rate':(0.001, 0.1),   # Reduced range\n",
    "    'batch_size': (200, 500),       # Reduced upper limit\n",
    "    'epochs':(20, 200),              # Reduced upper limit\n",
    "    'layers1':(1,2),                # Simplified to 1 or 2 layers\n",
    "    'layers2':(1,2),                # Simplified to 1 or 2 layers\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=100)\n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf865264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softsign',\n",
       " 'batch_size': 485,\n",
       " 'dropout': 0.7319939418114051,\n",
       " 'dropout_rate': 0.17959754525911098,\n",
       " 'epochs': 48,\n",
       " 'kernel': 1.3119890406724053,\n",
       " 'layers1': 1,\n",
       " 'layers2': 2,\n",
       " 'learning_rate': 0.06051038616257767,\n",
       " 'neurons': 38,\n",
       " 'normalization': 0.020584494295802447,\n",
       " 'optimizer': <keras.src.optimizers.ftrl.Ftrl at 0x17c5ba25d10>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best parameters\n",
    "optimum = nn_opt.max['params']\n",
    "learning_rate = optimum['learning_rate']\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "               'elu', 'exponential', LeakyReLU,'relu']\n",
    "optimum['activation'] = activationL[round(optimum['activation'])]\n",
    "optimum['batch_size'] = round(optimum['batch_size']) \n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','Adam']\n",
    "optimizerD= {'Adam':Adam(learning_rate=learning_rate), 'SGD':SGD(learning_rate=learning_rate),\n",
    "             'RMSprop':RMSprop(learning_rate=learning_rate), 'Adadelta':Adadelta(learning_rate=learning_rate),\n",
    "             'Adagrad':Adagrad(learning_rate=learning_rate), 'Adamax':Adamax(learning_rate=learning_rate),\n",
    "             'Nadam':Nadam(learning_rate=learning_rate), 'Ftrl':Ftrl(learning_rate=learning_rate)}\n",
    "optimum['optimizer'] = optimizerD[optimizerL[round(optimum['optimizer'])]]\n",
    "optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf9e7a",
   "metadata": {},
   "source": [
    "## Create a Keras layered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "067a483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Turn y_test into one-hot format.\n",
    "\n",
    "y_test=tf.keras.utils.to_categorical(y_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd0947",
   "metadata": {},
   "source": [
    "## 04. CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b402a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN parameters with optimums returned by Bayesian Optimization.\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "activation = 'softsign'\n",
    "batch_size = optimum['batch_size']\n",
    "dropout = optimum['dropout']\n",
    "dropout_rate = optimum['dropout_rate']\n",
    "epochs = optimum['epochs']\n",
    "kernel = 1 # Running optimum['kernel'] threw a ValueError on the CNN model below that stated the kernel_size argument must be a whole integer. I rounded the 'kernel' output above down to 1.\n",
    "layers1 = 1 \n",
    "layers2 = 2 \n",
    "learning_rate = optimum['learning_rate']\n",
    "neurons = 38 # Must be a whole integer for the CNN model\n",
    "normalization = optimum['normalization']\n",
    "optimizer = optimum['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "980b8acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quinn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create CNN model with above optimum parameters.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "if normalization > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "for i in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "if dropout > 0.5:\n",
    "    model.add(Dropout(dropout_rate, seed=123))\n",
    "for i in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea39fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7131 - loss: 0.8439\n",
      "Loss: 0.8411258459091187 Accuracy 0.7162153720855713\n"
     ]
    }
   ],
   "source": [
    "# Run model.\n",
    "\n",
    "model.fit(X_train,y_train,batch_size=485, epochs=48,verbose=0)\n",
    "acc = model.evaluate(X_train,y_train)\n",
    "print('Loss:', acc[0], 'Accuracy', acc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed439e09",
   "metadata": {},
   "source": [
    "#### Notes: smaller loss and accuracy increased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ef9f4",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfe9e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cities.\n",
    "cities = [\n",
    "    \"Basel\",\n",
    "    \"Belgrade\",\n",
    "    \"Budapest\",\n",
    "    \"Debilt\",\n",
    "    \"Dusseldorf\",\n",
    "    \"Heathrow\",\n",
    "    \"Kassel\",\n",
    "    \"Ljubljana\",\n",
    "    \"Maastricht\",\n",
    "    \"Madrid\",\n",
    "    \"Munchen\",\n",
    "    \"Oslo\",\n",
    "    \"Sonnblick\",\n",
    "    \"Stockholm\",\n",
    "    \"Valentia\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0259e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define confusion matrix to see results.\n",
    "\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([cities[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([cities[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d1bb9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Pred        Basel  Belgrade  Madrid\n",
      "True                               \n",
      "Basel        4220       222       5\n",
      "Belgrade      664       640       1\n",
      "Budapest      164        74       7\n",
      "Debilt         79        16       1\n",
      "Dusseldorf     23         8       1\n",
      "Heathrow       71        14      14\n",
      "Kassel         10         3       0\n",
      "Ljubljana      55         8       8\n",
      "Maastricht      9         0       0\n",
      "Madrid        474        51      21\n",
      "Munchen         8         0       0\n",
      "Oslo            4         2       1\n",
      "Stockholm       1         3       0\n",
      "Valentia        3         0       0\n"
     ]
    }
   ],
   "source": [
    "# Print results.\n",
    "\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d4f99",
   "metadata": {},
   "source": [
    "####  The model only recognized 3 cities. The accuracy score for the given confusion matrix is approximately 71.62%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
